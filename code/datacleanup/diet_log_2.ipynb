{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe713455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io, csv, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "pd.set_option(\"display.width\", 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1285cf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write safety guard: disabled by default\n",
    "WRITE_ENABLED = False\n",
    "TMP_DIR = \"/Users/clee/Documents/Lab/mlife/data/tmp\"\n",
    "os.makedirs(TMP_DIR, exist_ok=True)\n",
    "\n",
    "if not hasattr(pd.DataFrame, \"_to_csv_original\"):\n",
    "    pd.DataFrame._to_csv_original = pd.DataFrame.to_csv\n",
    "\n",
    "def _guarded_to_csv(self, path_or_buf=None, *args, **kwargs):\n",
    "    path_str = str(path_or_buf) if path_or_buf is not None else \"\"\n",
    "    if not WRITE_ENABLED:\n",
    "        print(f\"[SKIP WRITE] to_csv disabled. Target: {path_str}\")\n",
    "        return\n",
    "    if isinstance(path_or_buf, str) and \"/data/cleaned/\" in path_str:\n",
    "        print(f\"[REDIRECT] cleaned -> tmp for: {path_str}\")\n",
    "        path_str = path_str.replace(\"/data/cleaned/\", \"/data/tmp/\")\n",
    "        os.makedirs(os.path.dirname(path_str), exist_ok=True)\n",
    "        return pd.DataFrame._to_csv_original(self, path_str, *args, **kwargs)\n",
    "    return pd.DataFrame._to_csv_original(self, path_or_buf, *args, **kwargs)\n",
    "\n",
    "pd.DataFrame.to_csv = _guarded_to_csv\n",
    "\n",
    "def enable_writes(enabled: bool = False):\n",
    "    global WRITE_ENABLED\n",
    "    WRITE_ENABLED = bool(enabled)\n",
    "    print(\"WRITE_ENABLED =\", WRITE_ENABLED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c39218a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default read_csv failed, trying python engine: Error tokenizing data. C error: Expected 35 fields in line 8, saw 50\n",
      "\n",
      "Participants: 106\n",
      "Date range: 1969-12-31 -> 2023-07-06\n",
      "Participants: 106\n",
      "Date range: 1969-12-31 -> 2023-07-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kcal</th>\n",
       "      <td>18824.0</td>\n",
       "      <td>1217.221722</td>\n",
       "      <td>3030.332488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>802.675</td>\n",
       "      <td>1172.65</td>\n",
       "      <td>1508.65</td>\n",
       "      <td>404259.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protein_g</th>\n",
       "      <td>18824.0</td>\n",
       "      <td>57.134658</td>\n",
       "      <td>338.486254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.500</td>\n",
       "      <td>52.20</td>\n",
       "      <td>70.90</td>\n",
       "      <td>46245.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carbs_g</th>\n",
       "      <td>18824.0</td>\n",
       "      <td>132.191500</td>\n",
       "      <td>202.513794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.600</td>\n",
       "      <td>120.80</td>\n",
       "      <td>171.00</td>\n",
       "      <td>24630.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fat_g</th>\n",
       "      <td>18824.0</td>\n",
       "      <td>53.337665</td>\n",
       "      <td>106.050420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.500</td>\n",
       "      <td>48.80</td>\n",
       "      <td>68.30</td>\n",
       "      <td>13497.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sugars_g</th>\n",
       "      <td>18824.0</td>\n",
       "      <td>47.566309</td>\n",
       "      <td>48.789604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.300</td>\n",
       "      <td>37.80</td>\n",
       "      <td>64.00</td>\n",
       "      <td>2358.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fiber_g</th>\n",
       "      <td>18824.0</td>\n",
       "      <td>13.963908</td>\n",
       "      <td>34.812875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.500</td>\n",
       "      <td>11.20</td>\n",
       "      <td>17.30</td>\n",
       "      <td>4112.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_count</th>\n",
       "      <td>18824.0</td>\n",
       "      <td>7.534530</td>\n",
       "      <td>4.177410</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>7.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count         mean          std  min      25%      50%      75%       max\n",
       "kcal        18824.0  1217.221722  3030.332488  0.0  802.675  1172.65  1508.65  404259.3\n",
       "protein_g   18824.0    57.134658   338.486254  0.0   34.500    52.20    70.90   46245.2\n",
       "carbs_g     18824.0   132.191500   202.513794  0.0   75.600   120.80   171.00   24630.3\n",
       "fat_g       18824.0    53.337665   106.050420  0.0   30.500    48.80    68.30   13497.2\n",
       "sugars_g    18824.0    47.566309    48.789604  0.0   19.300    37.80    64.00    2358.7\n",
       "fiber_g     18824.0    13.963908    34.812875  0.0    6.500    11.20    17.30    4112.4\n",
       "item_count  18824.0     7.534530     4.177410  1.0    4.000     7.00    10.00      33.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAW_PATH = \"/Users/clee/Documents/Lab/mlife/data/raw/diet_log.csv\"\n",
    "CLEAN_DIR = \"/Users/clee/Documents/Lab/mlife/data/cleaned\"\n",
    "os.makedirs(CLEAN_DIR, exist_ok=True)\n",
    "\n",
    "def _stitch_csv_lines(p, encoding=\"utf-8\"):\n",
    "    with open(p, \"r\", encoding=encoding, errors=\"replace\", newline=\"\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "    out, buf = [], []\n",
    "    def balanced(s):\n",
    "        return s.count('\"') % 2 == 0\n",
    "    for line in raw:\n",
    "        if not buf:\n",
    "            buf = [line]\n",
    "            if balanced(line):\n",
    "                out.append(line); buf = []\n",
    "        else:\n",
    "            buf.append(line)\n",
    "            if balanced(\"\\n\".join(buf)):\n",
    "                out.append(\"\\n\".join(buf)); buf = []\n",
    "    if buf: out.append(\"\\n\".join(buf))\n",
    "    return out\n",
    "\n",
    "def read_diet_csv(p: str) -> pd.DataFrame:\n",
    "    try:\n",
    "        return pd.read_csv(p)\n",
    "    except Exception as e1:\n",
    "        print(\"Default read_csv failed, trying python engine:\", e1)\n",
    "    try:\n",
    "        return pd.read_csv(\n",
    "            p,\n",
    "            engine=\"python\",\n",
    "            quotechar='\"',\n",
    "            doublequote=True,\n",
    "            escapechar='\\\\',\n",
    "            on_bad_lines=\"skip\",\n",
    "        )\n",
    "    except Exception as e2:\n",
    "        print(\"Python engine failed, attempting stitched lines + csv.reader:\", e2)\n",
    "    lines = _stitch_csv_lines(p)\n",
    "    reader = csv.reader(io.StringIO(\"\\n\".join(lines)), delimiter=\",\", quotechar='\"', doublequote=True, escapechar='\\\\')\n",
    "    rows = [r for r in reader]\n",
    "    rows = [r for r in rows if any(cell.strip() for cell in r)]\n",
    "    if not rows:\n",
    "        raise ValueError(\"No rows parsed from CSV.\")\n",
    "    header = rows[0]\n",
    "    body = rows[1:]\n",
    "    hlen = len(header)\n",
    "    fixed = []\n",
    "    too_short = too_long = 0\n",
    "    for r in body:\n",
    "        if len(r) < hlen:\n",
    "            too_short += 1\n",
    "            r = r + [\"\"] * (hlen - len(r))\n",
    "        elif len(r) > hlen:\n",
    "            too_long += 1\n",
    "            r = r[:hlen]\n",
    "        fixed.append(r)\n",
    "    if too_short or too_long:\n",
    "        print(f\"Adjusted rows -> padded: {too_short}, truncated: {too_long}\")\n",
    "    return pd.DataFrame(fixed, columns=header)\n",
    "\n",
    "df = read_diet_csv(RAW_PATH)\n",
    "\n",
    "def canon(s: str) -> str:\n",
    "    s = str(s).strip().lower()\n",
    "    s = re.sub(r\"[\\s\\-]+\", \"_\", s)\n",
    "    s = re.sub(r\"[^a-z0-9_]\", \"\", s)\n",
    "    return s\n",
    "\n",
    "cols = list(df.columns)\n",
    "canon_map = {canon(c): c for c in cols}\n",
    "\n",
    "def find_col(candidates):\n",
    "    for c in candidates:\n",
    "        cc = canon(c)\n",
    "        if cc in canon_map:\n",
    "            return canon_map[cc]\n",
    "    return None\n",
    "\n",
    "DATE_CANDS = [\"date\", \"logged_date\", \"log_date\", \"created_at\", \"added_on\", \"added on\", \"timestamp\"]\n",
    "DATE_COL = find_col(DATE_CANDS)\n",
    "PID_CANDS = [\"participant_id\", \"participant\", \"user_id\", \"uid\", \"subject_id\", \"pid\", \"participant id\"]\n",
    "PNAME_CANDS = [\"participant_name\", \"participant name\", \"name\", \"user_name\", \"display_name\"]\n",
    "PID_COL = find_col(PID_CANDS)\n",
    "PNAME_COL = find_col(PNAME_CANDS)\n",
    "FOOD_CANDS = [\"food_name\", \"food name\", \"item_name\", \"food\", \"entry_name\", \"name\"]\n",
    "MEAL_CANDS = [\"meal\", \"meal_type\", \"meal type\", \"meal_name\", \"category\"]\n",
    "QTY_CANDS = [\"qty\", \"quantity\", \"serving_qty\", \"serving qty\", \"amount\"]\n",
    "SERV_CANDS = [\"serving_type\", \"serving type\", \"serving_unit\", \"unit\", \"unit_name\"]\n",
    "FOOD_COL = find_col(FOOD_CANDS)\n",
    "MEAL_COL = find_col(MEAL_CANDS)\n",
    "QTY_COL  = find_col(QTY_CANDS)\n",
    "SERV_COL = find_col(SERV_CANDS)\n",
    "\n",
    "if DATE_COL is not None:\n",
    "    df[\"datetime_raw\"] = pd.to_datetime(df[DATE_COL], errors=\"coerce\", utc=False)\n",
    "    df[\"date\"] = df[\"datetime_raw\"].dt.date\n",
    "    df[\"year\"] = pd.to_numeric(df[\"datetime_raw\"].dt.year, errors=\"coerce\")\n",
    "    df[\"month\"] = pd.to_numeric(df[\"datetime_raw\"].dt.month, errors=\"coerce\")\n",
    "    df[\"dow\"] = df[\"datetime_raw\"].dt.day_name()\n",
    "else:\n",
    "    print(\"No recognizable date column found.\")\n",
    "\n",
    "if PID_COL is None and PNAME_COL is not None:\n",
    "    df[\"participant_id\"] = df[PNAME_COL].astype(str)\n",
    "elif PID_COL is not None:\n",
    "    df[\"participant_id\"] = df[PID_COL].astype(str)\n",
    "else:\n",
    "    df[\"participant_id\"] = \"unknown\"\n",
    "\n",
    "if FOOD_COL is not None:\n",
    "    df[\"food_name\"] = df[FOOD_COL].astype(str)\n",
    "if MEAL_COL is not None:\n",
    "    df[\"meal\"] = df[MEAL_COL].astype(str).str.strip().str.lower().replace({\"b\": \"breakfast\", \"breakfast\": \"breakfast\", \"l\": \"lunch\", \"lnch\": \"lunch\", \"d\": \"dinner\", \"din\": \"dinner\", \"snack\": \"snack\", \"snacks\": \"snack\"})\n",
    "if QTY_COL is not None:\n",
    "    df[\"qty\"] = pd.to_numeric(df[QTY_COL], errors=\"coerce\")\n",
    "if SERV_COL is not None:\n",
    "    df[\"serving_type\"] = df[SERV_COL].astype(str)\n",
    "\n",
    "subset = [c for c in [\"participant_id\", \"date\", \"food_name\", \"qty\", \"serving_type\"] if c in df.columns]\n",
    "if len(subset) >= 2:\n",
    "    df = df.drop_duplicates(subset=subset, keep=\"first\")\n",
    "\n",
    "col_by_canon = {canon(c): c for c in df.columns}\n",
    "\n",
    "def find_col_by_canon(candidates):\n",
    "    for c in candidates:\n",
    "        cc = canon(c)\n",
    "        if cc in col_by_canon:\n",
    "            return col_by_canon[cc]\n",
    "    return None\n",
    "\n",
    "NUTRIENT_CANDIDATES = {\n",
    "    \"kcal\": [\"nf calories\", \"calories\", \"kcal\", \"energy_kcal\", \"og kcal\"],\n",
    "    \"protein_g\": [\"nf protein\", \"protein_g\", \"protein\"],\n",
    "    \"carbs_g\": [\"nf total carbohydrate\", \"carbs_g\", \"carbohydrates_g\", \"carbs\"],\n",
    "    \"fat_g\": [\"nf total fat\", \"fat_g\", \"total_fat_g\", \"fat\"],\n",
    "    \"sugars_g\": [\"nf sugars\", \"sugars_g\", \"sugar_g\", \"sugar\"],\n",
    "    \"fiber_g\": [\"nf dietary fiber\", \"fiber_g\", \"dietary_fiber_g\", \"fiber\"],\n",
    "    \"sodium_mg\": [\"nf sodium\", \"sodium_mg\", \"sodium\"],\n",
    "    \"cholesterol_mg\": [\"nf cholesterol\", \"cholesterol_mg\", \"cholesterol\"],\n",
    "    \"potassium_mg\": [\"nf potassium\", \"potassium_mg\", \"potassium\"],\n",
    "}\n",
    "\n",
    "for std_col, cands in NUTRIENT_CANDIDATES.items():\n",
    "    src = find_col_by_canon(cands)\n",
    "    if src is None:\n",
    "        df[std_col] = np.nan\n",
    "    else:\n",
    "        df[std_col] = pd.to_numeric(df[src], errors=\"coerce\")\n",
    "\n",
    "keep_cols = []\n",
    "for c in [\"participant_id\", \"datetime_raw\", \"date\", \"year\", \"month\", \"dow\", \"meal\", \"food_name\", \"qty\", \"serving_type\"]:\n",
    "    if c in df.columns:\n",
    "        keep_cols.append(c)\n",
    "keep_cols += [c for c in [\"kcal\", \"protein_g\", \"carbs_g\", \"fat_g\", \"sugars_g\", \"fiber_g\", \"sodium_mg\", \"cholesterol_mg\", \"potassium_mg\"] if c in df.columns]\n",
    "\n",
    "rowlevel_out = os.path.join(CLEAN_DIR, \"diet_log_rowlevel_cleaned_v2.csv\")\n",
    "df[keep_cols].to_csv(rowlevel_out, index=False)\n",
    "\n",
    "base = df.copy()\n",
    "if \"date\" not in base.columns and \"datetime_raw\" in base.columns:\n",
    "    base[\"date\"] = base[\"datetime_raw\"].dt.date\n",
    "\n",
    "agg_group = [c for c in [\"participant_id\", \"date\"] if c in base.columns]\n",
    "if len(agg_group) < 2:\n",
    "    raise ValueError(\"Need participant_id and date to create daily aggregates.\")\n",
    "\n",
    "num_cols = [c for c in [\"kcal\", \"protein_g\", \"carbs_g\", \"fat_g\", \"sugars_g\", \"fiber_g\", \"sodium_mg\", \"cholesterol_mg\", \"potassium_mg\", \"qty\"] if c in base.columns]\n",
    "\n",
    "daily = base.groupby(agg_group)[num_cols].sum(min_count=1).reset_index()\n",
    "\n",
    "if \"kcal\" in daily.columns:\n",
    "    kcal = daily[\"kcal\"].replace(0, np.nan)\n",
    "    if \"carbs_g\" in daily and \"fat_g\" in daily and \"protein_g\" in daily:\n",
    "        kcal_from_macros = daily[\"carbs_g\"]*4 + daily[\"protein_g\"]*4 + daily[\"fat_g\"]*9\n",
    "        daily[\"macro_kcal_ratio\"] = (kcal_from_macros / kcal).clip(upper=5)\n",
    "        daily[\"carb_pct_kcal\"] = (daily[\"carbs_g\"]*4 / kcal).clip(upper=1)\n",
    "        daily[\"protein_pct_kcal\"] = (daily[\"protein_g\"]*4 / kcal).clip(upper=1)\n",
    "        daily[\"fat_pct_kcal\"] = (daily[\"fat_g\"]*9 / kcal).clip(upper=1)\n",
    "\n",
    "if \"food_name\" in base.columns:\n",
    "    item_counts = base.groupby(agg_group)[\"food_name\"].count().rename(\"item_count\").reset_index()\n",
    "    daily = daily.merge(item_counts, on=agg_group, how=\"left\")\n",
    "\n",
    "if \"meal\" in base.columns:\n",
    "    meal_ct = base.assign(_cnt=1).pivot_table(index=agg_group, columns=\"meal\", values=\"_cnt\", aggfunc=\"sum\", fill_value=0).add_prefix(\"meal_\").reset_index()\n",
    "    daily = daily.merge(meal_ct, on=agg_group, how=\"left\")\n",
    "\n",
    "ml_out = os.path.join(CLEAN_DIR, \"diet_log_daily_ml_ready.csv\")\n",
    "daily.to_csv(ml_out, index=False)\n",
    "\n",
    "summary_cols = [c for c in [\"kcal\", \"protein_g\", \"carbs_g\", \"fat_g\", \"sugars_g\", \"fiber_g\", \"item_count\"] if c in daily.columns]\n",
    "print(\"Participants:\", daily[\"participant_id\"].nunique())\n",
    "print(\"Date range:\", daily.get(\"date\").min(), \"->\", daily.get(\"date\").max())\n",
    "daily[summary_cols].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539ad9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default read_csv failed, trying python engine: Error tokenizing data. C error: Expected 35 fields in line 8, saw 50\n",
      "\n",
      "Loaded shape: (148242, 35)\n",
      "Loaded shape: (148242, 35)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diet Log ID</th>\n",
       "      <th>Participant name</th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Group</th>\n",
       "      <th>Date</th>\n",
       "      <th>Meal</th>\n",
       "      <th>Food Name</th>\n",
       "      <th>Thumb</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Qty</th>\n",
       "      <th>Serving Type</th>\n",
       "      <th>Nf Calories</th>\n",
       "      <th>Nf Total Fat</th>\n",
       "      <th>Nf Saturated Fat</th>\n",
       "      <th>Nf Cholesterol</th>\n",
       "      <th>Nf Sodium</th>\n",
       "      <th>Nf Total Carbohydrate</th>\n",
       "      <th>Nf Dietary Fiber</th>\n",
       "      <th>Nf Sugars</th>\n",
       "      <th>Nf Protein</th>\n",
       "      <th>Nf Potassium</th>\n",
       "      <th>Nf Added Sugars</th>\n",
       "      <th>Nf Trans Fatty Acid</th>\n",
       "      <th>Added On</th>\n",
       "      <th>Og Serving Weight Grams</th>\n",
       "      <th>Og Kcal</th>\n",
       "      <th>Og Unit</th>\n",
       "      <th>Sel Serving Qty</th>\n",
       "      <th>Sel Serving Weight Grams</th>\n",
       "      <th>Alt Measures</th>\n",
       "      <th>Full Nutrients</th>\n",
       "      <th>Nix Brand Id</th>\n",
       "      <th>Nix Brand Name</th>\n",
       "      <th>Nix Item Id</th>\n",
       "      <th>Nix Item Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>152340</td>\n",
       "      <td>user user 10</td>\n",
       "      <td>10</td>\n",
       "      <td>mLife+Points</td>\n",
       "      <td>06/30/2023</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>deli turkey</td>\n",
       "      <td>https://nix-tag-images.s3.amazonaws.com/855_th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>oz</td>\n",
       "      <td>95.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>46.8</td>\n",
       "      <td>1020.6</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>11.5</td>\n",
       "      <td>296.8</td>\n",
       "      <td>11.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>06/30/2023 10:20:46 pm</td>\n",
       "      <td>56.7</td>\n",
       "      <td>63.50</td>\n",
       "      <td>oz</td>\n",
       "      <td>2.00</td>\n",
       "      <td>56.7</td>\n",
       "      <td>[{\"serving_weight\":48,\"measure\":\"oz (1 serving...</td>\n",
       "      <td>[{\"attr_id\":203,\"value\":7.6545},{\"attr_id\":204...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>152341</td>\n",
       "      <td>user user 10</td>\n",
       "      <td>10</td>\n",
       "      <td>mLife+Points</td>\n",
       "      <td>06/30/2023</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>fruit salad</td>\n",
       "      <td>https://nix-tag-images.s3.amazonaws.com/1773_t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>cup</td>\n",
       "      <td>193.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>49</td>\n",
       "      <td>6.5</td>\n",
       "      <td>32.9</td>\n",
       "      <td>2.7</td>\n",
       "      <td>728.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "      <td>06/30/2023 10:20:46 pm</td>\n",
       "      <td>162.4</td>\n",
       "      <td>96.62</td>\n",
       "      <td>cup</td>\n",
       "      <td>1.00</td>\n",
       "      <td>162.4</td>\n",
       "      <td>[{\"serving_weight\":162.4,\"measure\":\"cup\",\"seq\"...</td>\n",
       "      <td>[{\"attr_id\":203,\"value\":1.3555},{\"attr_id\":204...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152342</td>\n",
       "      <td>user user 10</td>\n",
       "      <td>10</td>\n",
       "      <td>mLife+Points</td>\n",
       "      <td>06/30/2023</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>hummus</td>\n",
       "      <td>https://nix-tag-images.s3.amazonaws.com/636_th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "      <td>cup</td>\n",
       "      <td>99.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>227.4</td>\n",
       "      <td>8.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>136.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>06/30/2023 10:26:14 pm</td>\n",
       "      <td>60.0</td>\n",
       "      <td>99.60</td>\n",
       "      <td>cup</td>\n",
       "      <td>0.25</td>\n",
       "      <td>60.0</td>\n",
       "      <td>[{\"serving_weight\":15,\"measure\":\"tbsp\",\"seq\":1...</td>\n",
       "      <td>[{\"attr_id\":203,\"value\":4.74},{\"attr_id\":204,\"...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diet Log ID Participant name  Participant ID         Group        Date    Meal    Food Name                                              Thumb Brand Name  \\\n",
       "0       152340     user user 10              10  mLife+Points  06/30/2023   Lunch  deli turkey  https://nix-tag-images.s3.amazonaws.com/855_th...        NaN   \n",
       "1       152341     user user 10              10  mLife+Points  06/30/2023   Lunch  fruit salad  https://nix-tag-images.s3.amazonaws.com/1773_t...        NaN   \n",
       "2       152342     user user 10              10  mLife+Points  06/30/2023  Dinner       hummus  https://nix-tag-images.s3.amazonaws.com/636_th...        NaN   \n",
       "\n",
       "    Qty Serving Type Nf Calories Nf Total Fat Nf Saturated Fat Nf Cholesterol Nf Sodium Nf Total Carbohydrate Nf Dietary Fiber Nf Sugars Nf Protein  \\\n",
       "0     3           oz        95.3          2.6              0.1           46.8    1020.6                   6.5              0.3       3.4       11.5   \n",
       "1     2          cup       193.2          0.9              0.1              0       5.3                    49              6.5      32.9        2.7   \n",
       "2  0.25          cup        99.6          5.8              0.9              0     227.4                   8.6              3.6       4.7        4.7   \n",
       "\n",
       "  Nf Potassium Nf Added Sugars Nf Trans Fatty Acid                Added On  Og Serving Weight Grams  Og Kcal Og Unit  Sel Serving Qty  \\\n",
       "0        296.8            11.5                11.5  06/30/2023 10:20:46 pm                     56.7    63.50      oz             2.00   \n",
       "1        728.3             2.7                   0  06/30/2023 10:20:46 pm                    162.4    96.62     cup             1.00   \n",
       "2        136.8             4.7                 4.7  06/30/2023 10:26:14 pm                     60.0    99.60     cup             0.25   \n",
       "\n",
       "   Sel Serving Weight Grams                                       Alt Measures                                     Full Nutrients Nix Brand Id Nix Brand Name  \\\n",
       "0                      56.7  [{\"serving_weight\":48,\"measure\":\"oz (1 serving...  [{\"attr_id\":203,\"value\":7.6545},{\"attr_id\":204...          NaN            NaN   \n",
       "1                     162.4  [{\"serving_weight\":162.4,\"measure\":\"cup\",\"seq\"...  [{\"attr_id\":203,\"value\":1.3555},{\"attr_id\":204...          NaN            NaN   \n",
       "2                      60.0  [{\"serving_weight\":15,\"measure\":\"tbsp\",\"seq\":1...  [{\"attr_id\":203,\"value\":4.74},{\"attr_id\":204,\"...          NaN            NaN   \n",
       "\n",
       "  Nix Item Id Nix Item Name  \n",
       "0         NaN           NaN  \n",
       "1         NaN           NaN  \n",
       "2         NaN           NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _stitch_csv_lines(p, encoding=\"utf-8\"):\n",
    "    with open(p, \"r\", encoding=encoding, errors=\"replace\", newline=\"\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "    out, buf = [], []\n",
    "    def balanced(s):\n",
    "        return s.count('\"') % 2 == 0\n",
    "    for line in raw:\n",
    "        if not buf:\n",
    "            buf = [line]\n",
    "            if balanced(line):\n",
    "                out.append(line); buf = []\n",
    "        else:\n",
    "            buf.append(line)\n",
    "            if balanced(\"\\n\".join(buf)):\n",
    "                out.append(\"\\n\".join(buf)); buf = []\n",
    "    if buf: out.append(\"\\n\".join(buf))\n",
    "    return out\n",
    "\n",
    "\n",
    "def read_diet_csv(p: str) -> pd.DataFrame:\n",
    "    try:\n",
    "        return pd.read_csv(p)\n",
    "    except Exception as e1:\n",
    "        print(\"Default read_csv failed, trying python engine:\", e1)\n",
    "    try:\n",
    "        return pd.read_csv(\n",
    "            p,\n",
    "            engine=\"python\",\n",
    "            quotechar='\"',\n",
    "            doublequote=True,\n",
    "            escapechar='\\\\',\n",
    "            on_bad_lines=\"skip\",\n",
    "        )\n",
    "    except Exception as e2:\n",
    "        print(\"Python engine failed, attempting stitched lines + csv.reader:\", e2)\n",
    "    lines = _stitch_csv_lines(p)\n",
    "    reader = csv.reader(io.StringIO(\"\\n\".join(lines)), delimiter=\",\", quotechar='\"', doublequote=True, escapechar='\\\\')\n",
    "    rows = [r for r in reader]\n",
    "    rows = [r for r in rows if any(cell.strip() for cell in r)]\n",
    "    if not rows:\n",
    "        raise ValueError(\"No rows parsed from CSV.\")\n",
    "    header = rows[0]\n",
    "    body = rows[1:]\n",
    "    hlen = len(header)\n",
    "    fixed = []\n",
    "    too_short = too_long = 0\n",
    "    for r in body:\n",
    "        if len(r) < hlen:\n",
    "            too_short += 1\n",
    "            r = r + [\"\"] * (hlen - len(r))\n",
    "        elif len(r) > hlen:\n",
    "            too_long += 1\n",
    "            r = r[:hlen]\n",
    "        fixed.append(r)\n",
    "    if too_short or too_long:\n",
    "        print(f\"Adjusted rows -> padded: {too_short}, truncated: {too_long}\")\n",
    "    return pd.DataFrame(fixed, columns=header)\n",
    "\n",
    "\n",
    "df = read_diet_csv(RAW_PATH)\n",
    "print(\"Loaded shape:\", df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08aaca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns ( 35 ):\n",
      " ['Diet Log ID', 'Participant name', 'Participant ID', 'Group', 'Date', 'Meal', 'Food Name', 'Thumb', 'Brand Name', 'Qty', 'Serving Type', 'Nf Calories', 'Nf Total Fat', 'Nf Saturated Fat', 'Nf Cholesterol', 'Nf Sodium', 'Nf Total Carbohydrate', 'Nf Dietary Fiber', 'Nf Sugars', 'Nf Protein', 'Nf Potassium', 'Nf Added Sugars', 'Nf Trans Fatty Acid', 'Added On', 'Og Serving Weight Grams', 'Og Kcal', 'Og Unit', 'Sel Serving Qty', 'Sel Serving Weight Grams', 'Alt Measures', 'Full Nutrients', 'Nix Brand Id', 'Nix Brand Name', 'Nix Item Id', 'Nix Item Name']\n",
      "\n",
      "DTypes:\n",
      " Diet Log ID                   int64\n",
      "Participant name             object\n",
      "Participant ID                int64\n",
      "Group                        object\n",
      "Date                         object\n",
      "Meal                         object\n",
      "Food Name                    object\n",
      "Thumb                        object\n",
      "Brand Name                   object\n",
      "Qty                          object\n",
      "Serving Type                 object\n",
      "Nf Calories                  object\n",
      "Nf Total Fat                 object\n",
      "Nf Saturated Fat             object\n",
      "Nf Cholesterol               object\n",
      "Nf Sodium                    object\n",
      "Nf Total Carbohydrate        object\n",
      "Nf Dietary Fiber             object\n",
      "Nf Sugars                    object\n",
      "Nf Protein                   object\n",
      "Nf Potassium                 object\n",
      "Nf Added Sugars              object\n",
      "Nf Trans Fatty Acid          object\n",
      "Added On                     object\n",
      "Og Serving Weight Grams     float64\n",
      "Og Kcal                     float64\n",
      "Og Unit                      object\n",
      "Sel Serving Qty             float64\n",
      "Sel Serving Weight Grams    float64\n",
      "Alt Measures                 object\n",
      "Full Nutrients               object\n",
      "Nix Brand Id                 object\n",
      "Nix Brand Name               object\n",
      "Nix Item Id                  object\n",
      "Nix Item Name                object\n",
      "dtype: object\n",
      "\n",
      "Top non-null columns:\n",
      " Diet Log ID              148242\n",
      "Nf Cholesterol           148242\n",
      "Full Nutrients           148242\n",
      "Sel Serving Qty          148242\n",
      "Og Kcal                  148242\n",
      "Added On                 148242\n",
      "Nf Trans Fatty Acid      148242\n",
      "Nf Added Sugars          148242\n",
      "Nf Potassium             148242\n",
      "Nf Protein               148242\n",
      "Nf Sugars                148242\n",
      "Participant name         148242\n",
      "Nf Total Carbohydrate    148242\n",
      "Nf Sodium                148242\n",
      "Nf Dietary Fiber         148242\n",
      "Nf Saturated Fat         148242\n",
      "Thumb                    148242\n",
      "Participant ID           148242\n",
      "Group                    148242\n",
      "Nf Total Fat             148242\n",
      "dtype: int64\n",
      "\n",
      "Approx memory usage: 621.74 MB\n",
      "\n",
      "Approx memory usage: 621.74 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns (\", len(df.columns), \"):\\n\", list(df.columns))\n",
    "print(\"\\nDTypes:\\n\", df.dtypes)\n",
    "non_null = df.notnull().sum().sort_values(ascending=False)\n",
    "print(\"\\nTop non-null columns:\\n\", non_null.head(20))\n",
    "mem_mb = df.memory_usage(deep=True).sum() / (1024**2)\n",
    "print(f\"\\nApprox memory usage: {mem_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b55d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing</th>\n",
       "      <th>missing_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Brand Name</th>\n",
       "      <td>110837</td>\n",
       "      <td>74.767610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nix Item Name</th>\n",
       "      <td>107860</td>\n",
       "      <td>72.759407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nix Item Id</th>\n",
       "      <td>107859</td>\n",
       "      <td>72.758732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nix Brand Name</th>\n",
       "      <td>107859</td>\n",
       "      <td>72.758732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nix Brand Id</th>\n",
       "      <td>107859</td>\n",
       "      <td>72.758732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alt Measures</th>\n",
       "      <td>37954</td>\n",
       "      <td>25.602731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Og Unit</th>\n",
       "      <td>21742</td>\n",
       "      <td>14.666559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Og Serving Weight Grams</th>\n",
       "      <td>1206</td>\n",
       "      <td>0.813535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sel Serving Weight Grams</th>\n",
       "      <td>1206</td>\n",
       "      <td>0.813535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qty</th>\n",
       "      <td>31</td>\n",
       "      <td>0.020912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meal</th>\n",
       "      <td>9</td>\n",
       "      <td>0.006071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Food Name</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          missing  missing_%\n",
       "Brand Name                 110837  74.767610\n",
       "Nix Item Name              107860  72.759407\n",
       "Nix Item Id                107859  72.758732\n",
       "Nix Brand Name             107859  72.758732\n",
       "Nix Brand Id               107859  72.758732\n",
       "Alt Measures                37954  25.602731\n",
       "Og Unit                     21742  14.666559\n",
       "Og Serving Weight Grams      1206   0.813535\n",
       "Sel Serving Weight Grams     1206   0.813535\n",
       "Qty                            31   0.020912\n",
       "Meal                            9   0.006071\n",
       "Food Name                       1   0.000675"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss_ct = df.isna().sum()\n",
    "miss_pct = (df.isna().mean() * 100)\n",
    "missing = pd.DataFrame({\"missing\": miss_ct, \"missing_%\": miss_pct}).sort_values(\"missing_%\", ascending=False)\n",
    "missing[missing[\"missing\"] > 0].head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb3a19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DATE_COL': 'Date', 'PID_COL': 'participant_id', 'PNAME_COL': 'Participant name', 'FOOD_COL': 'Food Name', 'MEAL_COL': 'Meal', 'QTY_COL': 'Qty', 'SERV_COL': 'Serving Type'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def canon(s: str) -> str:\n",
    "    s = str(s).strip().lower()\n",
    "    s = re.sub(r\"[\\s\\-]+\", \"_\", s)\n",
    "    s = re.sub(r\"[^a-z0-9_]\", \"\", s)\n",
    "    return s\n",
    "cols = list(df.columns)\n",
    "canon_map = {canon(c): c for c in cols}\n",
    "\n",
    "def find_col(candidates):\n",
    "    for c in candidates:\n",
    "        cc = canon(c)\n",
    "        if cc in canon_map:\n",
    "            return canon_map[cc]\n",
    "    return None\n",
    "DATE_CANDS = [\"date\", \"logged_date\", \"log_date\", \"created_at\", \"added_on\", \"added on\", \"timestamp\"]\n",
    "DATE_COL = find_col(DATE_CANDS)\n",
    "PID_CANDS = [\"participant_id\", \"participant\", \"user_id\", \"uid\", \"subject_id\", \"pid\", \"participant id\"]\n",
    "PNAME_CANDS = [\"participant_name\", \"participant name\", \"name\", \"user_name\", \"display_name\"]\n",
    "PID_COL = find_col(PID_CANDS)\n",
    "PNAME_COL = find_col(PNAME_CANDS)\n",
    "FOOD_CANDS = [\"food_name\", \"food name\", \"item_name\", \"food\", \"entry_name\", \"name\"]\n",
    "MEAL_CANDS = [\"meal\", \"meal_type\", \"meal type\", \"meal_name\", \"category\"]\n",
    "QTY_CANDS = [\"qty\", \"quantity\", \"serving_qty\", \"serving qty\", \"amount\"]\n",
    "SERV_CANDS = [\"serving_type\", \"serving type\", \"serving_unit\", \"unit\", \"unit_name\"]\n",
    "FOOD_COL = find_col(FOOD_CANDS)\n",
    "MEAL_COL = find_col(MEAL_CANDS)\n",
    "QTY_COL  = find_col(QTY_CANDS)\n",
    "SERV_COL = find_col(SERV_CANDS)\n",
    "print({\"DATE_COL\": DATE_COL, \"PID_COL\": PID_COL, \"PNAME_COL\": PNAME_COL, \"FOOD_COL\": FOOD_COL, \"MEAL_COL\": MEAL_COL, \"QTY_COL\": QTY_COL, \"SERV_COL\": SERV_COL})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c429bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range: 1969-12-31 00:00:00 -> 2023-07-06 00:00:00\n",
      "Unparsed datetime rows: 14\n"
     ]
    }
   ],
   "source": [
    "if DATE_COL is not None:\n",
    "    df[\"datetime_raw\"] = pd.to_datetime(df[DATE_COL], errors=\"coerce\", utc=False)\n",
    "    df[\"date\"] = df[\"datetime_raw\"].dt.date\n",
    "    df[\"year\"] = pd.to_numeric(df[\"datetime_raw\"].dt.year, errors=\"coerce\")\n",
    "    df[\"month\"] = pd.to_numeric(df[\"datetime_raw\"].dt.month, errors=\"coerce\")\n",
    "    df[\"dow\"] = df[\"datetime_raw\"].dt.day_name()\n",
    "    print(\"Date range:\", df[\"datetime_raw\"].min(), \"->\", df[\"datetime_raw\"].max())\n",
    "    print(\"Unparsed datetime rows:\", df[\"datetime_raw\"].isna().sum())\n",
    "else:\n",
    "    print(\"No recognizable date column found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6058764c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique participants: 1\n"
     ]
    }
   ],
   "source": [
    "if PID_COL is None and PNAME_COL is not None:\n",
    "    df[\"participant_id\"] = df[PNAME_COL].astype(str)\n",
    "elif PID_COL is not None:\n",
    "    df[\"participant_id\"] = df[PID_COL].astype(str)\n",
    "else:\n",
    "    df[\"participant_id\"] = \"unknown\"\n",
    "n_ids = df[\"participant_id\"].nunique(dropna=True)\n",
    "print(\"Unique participants:\", n_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c8b392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food_name -> non-null: 148242\n",
      "meal -> non-null: 148242\n",
      "qty -> non-null: 147970\n",
      "serving_type -> non-null: 148242\n",
      "serving_type -> non-null: 148242\n"
     ]
    }
   ],
   "source": [
    "if FOOD_COL is not None: df[\"food_name\"] = df[FOOD_COL].astype(str)\n",
    "if MEAL_COL is not None:\n",
    "    df[\"meal\"] = df[MEAL_COL].astype(str).str.strip().str.lower().replace({\"b\": \"breakfast\", \"breakfast\": \"breakfast\", \"l\": \"lunch\", \"lnch\": \"lunch\", \"d\": \"dinner\", \"din\": \"dinner\", \"snack\": \"snack\", \"snacks\": \"snack\"})\n",
    "if QTY_COL is not None:\n",
    "    df[\"qty\"] = pd.to_numeric(df[QTY_COL], errors=\"coerce\")\n",
    "if SERV_COL is not None:\n",
    "    df[\"serving_type\"] = df[SERV_COL].astype(str)\n",
    "for col in [\"food_name\", \"meal\", \"qty\", \"serving_type\"]:\n",
    "    if col in df.columns:\n",
    "        print(col, \"-> non-null:\", df[col].notna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befab98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "meal_map = {\"breakfast\": 1, \"lunch\": 2, \"dinner\": 3, \"snack\": 4}\n",
    "if \"meal\" in df.columns:\n",
    "    df[\"meal_code\"] = (\n",
    "        df[\"meal\"].astype(str).str.strip().str.lower().map(meal_map).astype(\"Int64\")\n",
    "    )\n",
    "    print(df[\"meal_code\"].value_counts(dropna=False).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96165956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deduplicated 17039 rows using subset=['participant_id', 'date', 'food_name', 'qty', 'serving_type']\n"
     ]
    }
   ],
   "source": [
    "subset = [c for c in [\"participant_id\", \"date\", \"food_name\", \"qty\", \"serving_type\"] if c in df.columns]\n",
    "if len(subset) >= 2:\n",
    "    before = len(df)\n",
    "    df = df.drop_duplicates(subset=subset, keep=\"first\")\n",
    "    print(f\"Deduplicated {before - len(df)} rows using subset={subset}\")\n",
    "else:\n",
    "    print(\"Not enough normalized columns to deduplicate; skipping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718863c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kcal</th>\n",
       "      <td>131195.0</td>\n",
       "      <td>168.095174</td>\n",
       "      <td>1138.713233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>114.1</td>\n",
       "      <td>215.6</td>\n",
       "      <td>403650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protein_g</th>\n",
       "      <td>131195.0</td>\n",
       "      <td>7.935584</td>\n",
       "      <td>128.226399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>9.4</td>\n",
       "      <td>46215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carbs_g</th>\n",
       "      <td>131195.0</td>\n",
       "      <td>18.105401</td>\n",
       "      <td>74.157866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>26.1</td>\n",
       "      <td>24570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fat_g</th>\n",
       "      <td>131195.0</td>\n",
       "      <td>7.408812</td>\n",
       "      <td>39.613671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>10.3</td>\n",
       "      <td>13455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sugars_g</th>\n",
       "      <td>131195.0</td>\n",
       "      <td>6.478661</td>\n",
       "      <td>15.904234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fiber_g</th>\n",
       "      <td>131195.0</td>\n",
       "      <td>1.901895</td>\n",
       "      <td>12.885385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4095.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sodium_mg</th>\n",
       "      <td>131195.0</td>\n",
       "      <td>274.020421</td>\n",
       "      <td>2484.726208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>320.0</td>\n",
       "      <td>877500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cholesterol_mg</th>\n",
       "      <td>131195.0</td>\n",
       "      <td>28.239123</td>\n",
       "      <td>69.575463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3906.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>potassium_mg</th>\n",
       "      <td>131195.0</td>\n",
       "      <td>191.457604</td>\n",
       "      <td>331.926578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>102.6</td>\n",
       "      <td>257.1</td>\n",
       "      <td>47775.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count        mean          std  min   25%    50%    75%       max\n",
       "kcal            131195.0  168.095174  1138.713233  0.0  50.0  114.1  215.6  403650.0\n",
       "protein_g       131195.0    7.935584   128.226399  0.0   0.9    3.4    9.4   46215.0\n",
       "carbs_g         131195.0   18.105401    74.157866  0.0   2.0   11.0   26.1   24570.0\n",
       "fat_g           131195.0    7.408812    39.613671  0.0   0.3    3.5   10.3   13455.0\n",
       "sugars_g        131195.0    6.478661    15.904234  0.0   0.2    2.0    7.5    2340.0\n",
       "fiber_g         131195.0    1.901895    12.885385  0.0   0.0    0.9    2.4    4095.0\n",
       "sodium_mg       131195.0  274.020421  2484.726208  0.0  15.0  106.7  320.0  877500.0\n",
       "cholesterol_mg  131195.0   28.239123    69.575463  0.0   0.0    0.0   25.0    3906.0\n",
       "potassium_mg    131195.0  191.457604   331.926578  0.0  21.5  102.6  257.1   47775.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    canon\n",
    "except NameError:\n",
    "    import re\n",
    "    def canon(s: str) -> str:\n",
    "        s = str(s).strip().lower()\n",
    "        s = re.sub(r\"[\\s\\-]+\", \"_\", s)\n",
    "        s = re.sub(r\"[^a-z0-9_]\", \"\", s)\n",
    "        return s\n",
    "\n",
    "col_by_canon = {canon(c): c for c in df.columns}\n",
    "\n",
    "def find_col_by_canon(candidates):\n",
    "    for c in candidates:\n",
    "        cc = canon(c)\n",
    "        if cc in col_by_canon:\n",
    "            return col_by_canon[cc]\n",
    "    return None\n",
    "\n",
    "NUTRIENT_CANDIDATES = {\n",
    "    \"kcal\": [\"nf calories\", \"calories\", \"kcal\", \"energy_kcal\", \"og kcal\"],\n",
    "    \"protein_g\": [\"nf protein\", \"protein_g\", \"protein\"],\n",
    "    \"carbs_g\": [\"nf total carbohydrate\", \"carbs_g\", \"carbohydrates_g\", \"carbs\"],\n",
    "    \"fat_g\": [\"nf total fat\", \"fat_g\", \"total_fat_g\", \"fat\"],\n",
    "    \"sugars_g\": [\"nf sugars\", \"sugars_g\", \"sugar_g\", \"sugar\"],\n",
    "    \"fiber_g\": [\"nf dietary fiber\", \"fiber_g\", \"dietary_fiber_g\", \"fiber\"],\n",
    "    \"sodium_mg\": [\"nf sodium\", \"sodium_mg\", \"sodium\"],\n",
    "    \"cholesterol_mg\": [\"nf cholesterol\", \"cholesterol_mg\", \"cholesterol\"],\n",
    "    \"potassium_mg\": [\"nf potassium\", \"potassium_mg\", \"potassium\"],\n",
    "}\n",
    "\n",
    "for std_col, cands in NUTRIENT_CANDIDATES.items():\n",
    "    src = find_col_by_canon(cands)\n",
    "    if src is None:\n",
    "        df[std_col] = np.nan\n",
    "    else:\n",
    "        df[std_col] = pd.to_numeric(df[src], errors=\"coerce\")\n",
    "\n",
    "nutrient_cols = list(NUTRIENT_CANDIDATES.keys())\n",
    "df[nutrient_cols].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6688ec51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /Users/clee/Documents/Lab/mlife/data/cleaned/diet_log_rowlevel_cleaned_v2.csv with 131203 rows and 19 cols\n"
     ]
    }
   ],
   "source": [
    "keep_cols = []\n",
    "for c in [\"participant_id\", \"datetime_raw\", \"date\", \"year\", \"month\", \"dow\", \"meal\", \"food_name\", \"qty\", \"serving_type\"]:\n",
    "    if c in df.columns: keep_cols.append(c)\n",
    "keep_cols += [c for c in [\"kcal\", \"protein_g\", \"carbs_g\", \"fat_g\", \"sugars_g\", \"fiber_g\", \"sodium_mg\", \"cholesterol_mg\", \"potassium_mg\"] if c in df.columns]\n",
    "rowlevel_out = os.path.join(CLEAN_DIR, \"diet_log_rowlevel_cleaned_v2.csv\")\n",
    "df[keep_cols].to_csv(rowlevel_out, index=False)\n",
    "print(\"Wrote:\", rowlevel_out, \"with\", len(df), \"rows and\", len(keep_cols), \"cols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4593376f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /Users/clee/Documents/Lab/mlife/data/cleaned/diet_log_daily_ml_ready.csv with 377 rows and 22 cols\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>date</th>\n",
       "      <th>kcal</th>\n",
       "      <th>protein_g</th>\n",
       "      <th>carbs_g</th>\n",
       "      <th>fat_g</th>\n",
       "      <th>sugars_g</th>\n",
       "      <th>fiber_g</th>\n",
       "      <th>sodium_mg</th>\n",
       "      <th>cholesterol_mg</th>\n",
       "      <th>potassium_mg</th>\n",
       "      <th>qty</th>\n",
       "      <th>macro_kcal_ratio</th>\n",
       "      <th>carb_pct_kcal</th>\n",
       "      <th>protein_pct_kcal</th>\n",
       "      <th>fat_pct_kcal</th>\n",
       "      <th>item_count</th>\n",
       "      <th>meal_breakfast</th>\n",
       "      <th>meal_dinner</th>\n",
       "      <th>meal_lunch</th>\n",
       "      <th>meal_nan</th>\n",
       "      <th>meal_snack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unknown</td>\n",
       "      <td>1969-12-31</td>\n",
       "      <td>7761.2</td>\n",
       "      <td>401.6</td>\n",
       "      <td>707.3</td>\n",
       "      <td>376.7</td>\n",
       "      <td>238.6</td>\n",
       "      <td>53.2</td>\n",
       "      <td>14246.7</td>\n",
       "      <td>1557.9</td>\n",
       "      <td>7576.6</td>\n",
       "      <td>625.590</td>\n",
       "      <td>1.008336</td>\n",
       "      <td>0.364531</td>\n",
       "      <td>0.206978</td>\n",
       "      <td>0.436827</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unknown</td>\n",
       "      <td>2022-06-25</td>\n",
       "      <td>1492.3</td>\n",
       "      <td>68.1</td>\n",
       "      <td>135.3</td>\n",
       "      <td>82.7</td>\n",
       "      <td>63.7</td>\n",
       "      <td>30.6</td>\n",
       "      <td>2770.6</td>\n",
       "      <td>214.6</td>\n",
       "      <td>1174.8</td>\n",
       "      <td>10.830</td>\n",
       "      <td>1.043959</td>\n",
       "      <td>0.362662</td>\n",
       "      <td>0.182537</td>\n",
       "      <td>0.498760</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unknown</td>\n",
       "      <td>2022-06-26</td>\n",
       "      <td>5597.8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>575.2</td>\n",
       "      <td>215.5</td>\n",
       "      <td>296.9</td>\n",
       "      <td>68.1</td>\n",
       "      <td>7824.4</td>\n",
       "      <td>1168.6</td>\n",
       "      <td>8455.9</td>\n",
       "      <td>41.570</td>\n",
       "      <td>0.974722</td>\n",
       "      <td>0.411019</td>\n",
       "      <td>0.217228</td>\n",
       "      <td>0.346475</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unknown</td>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>76323.4</td>\n",
       "      <td>3720.3</td>\n",
       "      <td>7654.7</td>\n",
       "      <td>3450.3</td>\n",
       "      <td>2943.2</td>\n",
       "      <td>745.9</td>\n",
       "      <td>112184.6</td>\n",
       "      <td>11969.1</td>\n",
       "      <td>86952.7</td>\n",
       "      <td>1177.100</td>\n",
       "      <td>1.003004</td>\n",
       "      <td>0.401172</td>\n",
       "      <td>0.194976</td>\n",
       "      <td>0.406857</td>\n",
       "      <td>378</td>\n",
       "      <td>99</td>\n",
       "      <td>120</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unknown</td>\n",
       "      <td>2022-06-28</td>\n",
       "      <td>103483.5</td>\n",
       "      <td>5063.5</td>\n",
       "      <td>10544.3</td>\n",
       "      <td>4557.7</td>\n",
       "      <td>3788.7</td>\n",
       "      <td>1189.6</td>\n",
       "      <td>171967.1</td>\n",
       "      <td>17989.5</td>\n",
       "      <td>142221.0</td>\n",
       "      <td>3237.981</td>\n",
       "      <td>0.999681</td>\n",
       "      <td>0.407574</td>\n",
       "      <td>0.195722</td>\n",
       "      <td>0.396385</td>\n",
       "      <td>692</td>\n",
       "      <td>182</td>\n",
       "      <td>191</td>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>unknown</td>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>125146.7</td>\n",
       "      <td>5814.3</td>\n",
       "      <td>12913.9</td>\n",
       "      <td>5642.8</td>\n",
       "      <td>4557.4</td>\n",
       "      <td>1406.7</td>\n",
       "      <td>212468.5</td>\n",
       "      <td>20839.4</td>\n",
       "      <td>162620.1</td>\n",
       "      <td>3917.350</td>\n",
       "      <td>1.004405</td>\n",
       "      <td>0.412760</td>\n",
       "      <td>0.185839</td>\n",
       "      <td>0.405805</td>\n",
       "      <td>772</td>\n",
       "      <td>216</td>\n",
       "      <td>232</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>unknown</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>124635.8</td>\n",
       "      <td>5487.5</td>\n",
       "      <td>14049.7</td>\n",
       "      <td>5342.1</td>\n",
       "      <td>5726.4</td>\n",
       "      <td>1397.0</td>\n",
       "      <td>212183.6</td>\n",
       "      <td>18688.9</td>\n",
       "      <td>151778.3</td>\n",
       "      <td>4081.410</td>\n",
       "      <td>1.012772</td>\n",
       "      <td>0.450904</td>\n",
       "      <td>0.176113</td>\n",
       "      <td>0.385755</td>\n",
       "      <td>763</td>\n",
       "      <td>175</td>\n",
       "      <td>232</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>unknown</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>128070.9</td>\n",
       "      <td>5198.1</td>\n",
       "      <td>14714.9</td>\n",
       "      <td>5611.9</td>\n",
       "      <td>5953.7</td>\n",
       "      <td>1380.4</td>\n",
       "      <td>199886.2</td>\n",
       "      <td>17132.4</td>\n",
       "      <td>132123.1</td>\n",
       "      <td>4928.740</td>\n",
       "      <td>1.016305</td>\n",
       "      <td>0.459586</td>\n",
       "      <td>0.162351</td>\n",
       "      <td>0.394368</td>\n",
       "      <td>745</td>\n",
       "      <td>182</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>unknown</td>\n",
       "      <td>2022-07-02</td>\n",
       "      <td>127526.7</td>\n",
       "      <td>5294.3</td>\n",
       "      <td>13406.0</td>\n",
       "      <td>5606.9</td>\n",
       "      <td>5003.4</td>\n",
       "      <td>1260.3</td>\n",
       "      <td>215925.4</td>\n",
       "      <td>20092.9</td>\n",
       "      <td>137815.7</td>\n",
       "      <td>4185.996</td>\n",
       "      <td>0.982252</td>\n",
       "      <td>0.420492</td>\n",
       "      <td>0.166061</td>\n",
       "      <td>0.395698</td>\n",
       "      <td>724</td>\n",
       "      <td>202</td>\n",
       "      <td>232</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>unknown</td>\n",
       "      <td>2022-07-03</td>\n",
       "      <td>113521.4</td>\n",
       "      <td>5403.3</td>\n",
       "      <td>11748.4</td>\n",
       "      <td>4870.8</td>\n",
       "      <td>4503.2</td>\n",
       "      <td>1097.3</td>\n",
       "      <td>186426.8</td>\n",
       "      <td>20992.1</td>\n",
       "      <td>140251.0</td>\n",
       "      <td>2558.220</td>\n",
       "      <td>0.990509</td>\n",
       "      <td>0.413962</td>\n",
       "      <td>0.190389</td>\n",
       "      <td>0.386158</td>\n",
       "      <td>706</td>\n",
       "      <td>182</td>\n",
       "      <td>209</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id        date      kcal  protein_g  carbs_g   fat_g  sugars_g  fiber_g  sodium_mg  cholesterol_mg  potassium_mg       qty  macro_kcal_ratio  \\\n",
       "0        unknown  1969-12-31    7761.2      401.6    707.3   376.7     238.6     53.2    14246.7          1557.9        7576.6   625.590          1.008336   \n",
       "1        unknown  2022-06-25    1492.3       68.1    135.3    82.7      63.7     30.6     2770.6           214.6        1174.8    10.830          1.043959   \n",
       "2        unknown  2022-06-26    5597.8      304.0    575.2   215.5     296.9     68.1     7824.4          1168.6        8455.9    41.570          0.974722   \n",
       "3        unknown  2022-06-27   76323.4     3720.3   7654.7  3450.3    2943.2    745.9   112184.6         11969.1       86952.7  1177.100          1.003004   \n",
       "4        unknown  2022-06-28  103483.5     5063.5  10544.3  4557.7    3788.7   1189.6   171967.1         17989.5      142221.0  3237.981          0.999681   \n",
       "5        unknown  2022-06-29  125146.7     5814.3  12913.9  5642.8    4557.4   1406.7   212468.5         20839.4      162620.1  3917.350          1.004405   \n",
       "6        unknown  2022-06-30  124635.8     5487.5  14049.7  5342.1    5726.4   1397.0   212183.6         18688.9      151778.3  4081.410          1.012772   \n",
       "7        unknown  2022-07-01  128070.9     5198.1  14714.9  5611.9    5953.7   1380.4   199886.2         17132.4      132123.1  4928.740          1.016305   \n",
       "8        unknown  2022-07-02  127526.7     5294.3  13406.0  5606.9    5003.4   1260.3   215925.4         20092.9      137815.7  4185.996          0.982252   \n",
       "9        unknown  2022-07-03  113521.4     5403.3  11748.4  4870.8    4503.2   1097.3   186426.8         20992.1      140251.0  2558.220          0.990509   \n",
       "\n",
       "   carb_pct_kcal  protein_pct_kcal  fat_pct_kcal  item_count  meal_breakfast  meal_dinner  meal_lunch  meal_nan  meal_snack  \n",
       "0       0.364531          0.206978      0.436827          38               6           20           8         0           4  \n",
       "1       0.362662          0.182537      0.498760           8               1            4           3         0           0  \n",
       "2       0.411019          0.217228      0.346475          26               5           10           9         0           2  \n",
       "3       0.401172          0.194976      0.406857         378              99          120          95         1          63  \n",
       "4       0.407574          0.195722      0.396385         692             182          191         194         0         125  \n",
       "5       0.412760          0.185839      0.405805         772             216          232         181         0         143  \n",
       "6       0.450904          0.176113      0.385755         763             175          232         221         0         135  \n",
       "7       0.459586          0.162351      0.394368         745             182          210         210         0         143  \n",
       "8       0.420492          0.166061      0.395698         724             202          232         166         0         124  \n",
       "9       0.413962          0.190389      0.386158         706             182          209         198         0         117  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = df.copy()\n",
    "if \"date\" not in base.columns and \"datetime_raw\" in base.columns:\n",
    "    base[\"date\"] = base[\"datetime_raw\"].dt.date\n",
    "agg_group = [c for c in [\"participant_id\", \"date\"] if c in base.columns]\n",
    "if len(agg_group) < 2:\n",
    "    raise ValueError(\"Need participant_id and date to create daily aggregates.\")\n",
    "num_cols = [c for c in [\"kcal\", \"protein_g\", \"carbs_g\", \"fat_g\", \"sugars_g\", \"fiber_g\", \"sodium_mg\", \"cholesterol_mg\", \"potassium_mg\", \"qty\"] if c in base.columns]\n",
    "daily = base.groupby(agg_group)[num_cols].sum(min_count=1).reset_index()\n",
    "if \"kcal\" in daily.columns:\n",
    "    kcal = daily[\"kcal\"].replace(0, np.nan)\n",
    "    if \"carbs_g\" in daily and \"fat_g\" in daily and \"protein_g\" in daily:\n",
    "        kcal_from_macros = daily[\"carbs_g\"]*4 + daily[\"protein_g\"]*4 + daily[\"fat_g\"]*9\n",
    "        daily[\"macro_kcal_ratio\"] = (kcal_from_macros / kcal).clip(upper=5)\n",
    "        daily[\"carb_pct_kcal\"] = (daily[\"carbs_g\"]*4 / kcal).clip(upper=1)\n",
    "        daily[\"protein_pct_kcal\"] = (daily[\"protein_g\"]*4 / kcal).clip(upper=1)\n",
    "        daily[\"fat_pct_kcal\"] = (daily[\"fat_g\"]*9 / kcal).clip(upper=1)\n",
    "if \"food_name\" in base.columns:\n",
    "    item_counts = base.groupby(agg_group)[\"food_name\"].count().rename(\"item_count\").reset_index()\n",
    "    daily = daily.merge(item_counts, on=agg_group, how=\"left\")\n",
    "if \"meal\" in base.columns:\n",
    "    meal_ct = base.assign(_cnt=1).pivot_table(index=agg_group, columns=\"meal\", values=\"_cnt\", aggfunc=\"sum\", fill_value=0).add_prefix(\"meal_\").reset_index()\n",
    "    daily = daily.merge(meal_ct, on=agg_group, how=\"left\")\n",
    "ml_out = os.path.join(CLEAN_DIR, \"diet_log_daily_ml_ready.csv\")\n",
    "daily.to_csv(ml_out, index=False)\n",
    "print(\"Wrote:\", ml_out, \"with\", len(daily), \"rows and\", daily.shape[1], \"cols\")\n",
    "daily.head(10)\n",
    "\n",
    "keep_cols = []\n",
    "for c in [\"participant_id\", \"datetime_raw\", \"date\", \"year\", \"month\", \"dow\", \"meal\", \"meal_code\", \"food_name\", \"qty\", \"serving_type\"]:\n",
    "    if c in df.columns: keep_cols.append(c)\n",
    "keep_cols += [c for c in [\"kcal\", \"protein_g\", \"carbs_g\", \"fat_g\", \"sugars_g\", \"fiber_g\", \"sodium_mg\", \"cholesterol_mg\", \"potassium_mg\"] if c in df.columns]\n",
    "rowlevel_out = os.path.join(CLEAN_DIR, \"diet_log_rowlevel_cleaned_v2.csv\")\n",
    "df[keep_cols].to_csv(rowlevel_out, index=False)\n",
    "print(\"Wrote:\", rowlevel_out, \"with\", len(df), \"rows and\", len(keep_cols), \"cols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b0ea24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participants: 1\n",
      "Date range: 1969-12-31 -> 2023-07-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kcal</th>\n",
       "      <td>377.0</td>\n",
       "      <td>58490.201857</td>\n",
       "      <td>33177.982282</td>\n",
       "      <td>1200.6</td>\n",
       "      <td>41978.8</td>\n",
       "      <td>50746.1</td>\n",
       "      <td>68713.8</td>\n",
       "      <td>526307.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protein_g</th>\n",
       "      <td>377.0</td>\n",
       "      <td>2761.363926</td>\n",
       "      <td>2762.950245</td>\n",
       "      <td>54.8</td>\n",
       "      <td>1891.2</td>\n",
       "      <td>2315.9</td>\n",
       "      <td>3209.0</td>\n",
       "      <td>51880.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carbs_g</th>\n",
       "      <td>377.0</td>\n",
       "      <td>6299.752255</td>\n",
       "      <td>2962.748946</td>\n",
       "      <td>135.3</td>\n",
       "      <td>4457.2</td>\n",
       "      <td>5480.1</td>\n",
       "      <td>7351.0</td>\n",
       "      <td>36914.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fat_g</th>\n",
       "      <td>377.0</td>\n",
       "      <td>2577.991512</td>\n",
       "      <td>1323.449916</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1891.1</td>\n",
       "      <td>2243.0</td>\n",
       "      <td>3040.8</td>\n",
       "      <td>19114.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sugars_g</th>\n",
       "      <td>377.0</td>\n",
       "      <td>2254.198939</td>\n",
       "      <td>999.256655</td>\n",
       "      <td>32.6</td>\n",
       "      <td>1611.9</td>\n",
       "      <td>1966.1</td>\n",
       "      <td>2647.7</td>\n",
       "      <td>7446.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fiber_g</th>\n",
       "      <td>377.0</td>\n",
       "      <td>661.779045</td>\n",
       "      <td>397.951104</td>\n",
       "      <td>30.6</td>\n",
       "      <td>424.7</td>\n",
       "      <td>531.5</td>\n",
       "      <td>804.2</td>\n",
       "      <td>5383.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_count</th>\n",
       "      <td>377.0</td>\n",
       "      <td>347.981432</td>\n",
       "      <td>151.354530</td>\n",
       "      <td>8.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>772.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count          mean           std     min      25%      50%      75%       max\n",
       "kcal        377.0  58490.201857  33177.982282  1200.6  41978.8  50746.1  68713.8  526307.1\n",
       "protein_g   377.0   2761.363926   2762.950245    54.8   1891.2   2315.9   3209.0   51880.4\n",
       "carbs_g     377.0   6299.752255   2962.748946   135.3   4457.2   5480.1   7351.0   36914.5\n",
       "fat_g       377.0   2577.991512   1323.449916    36.0   1891.1   2243.0   3040.8   19114.9\n",
       "sugars_g    377.0   2254.198939    999.256655    32.6   1611.9   1966.1   2647.7    7446.7\n",
       "fiber_g     377.0    661.779045    397.951104    30.6    424.7    531.5    804.2    5383.8\n",
       "item_count  377.0    347.981432    151.354530     8.0    246.0    295.0    433.0     772.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_cols = [c for c in [\"kcal\", \"protein_g\", \"carbs_g\", \"fat_g\", \"sugars_g\", \"fiber_g\", \"item_count\"] if c in daily.columns]\n",
    "print(\"Participants:\", daily[\"participant_id\"].nunique())\n",
    "print(\"Date range:\", daily.get(\"date\").min(), \"->\", daily.get(\"date\").max())\n",
    "daily[summary_cols].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d5befae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row-level rows per year:\n",
      "  year  row_count\n",
      "1969.0         39\n",
      "2022.0      93827\n",
      "2023.0      47964\n",
      "Daily rows per year:\n",
      " year  daily_row_count\n",
      " 1969                8\n",
      " 2022            11943\n",
      " 2023             6873\n"
     ]
    }
   ],
   "source": [
    "yrs_df = df.copy()\n",
    "if \"year\" not in yrs_df.columns:\n",
    "    if \"date\" in yrs_df.columns:\n",
    "        yrs_df[\"year\"] = pd.to_datetime(yrs_df[\"date\"], errors=\"coerce\").dt.year\n",
    "    elif \"datetime_raw\" in yrs_df.columns:\n",
    "        yrs_df[\"year\"] = pd.to_datetime(yrs_df[\"datetime_raw\"], errors=\"coerce\").dt.year\n",
    "row_counts = (\n",
    "    yrs_df.dropna(subset=[\"year\"]).groupby(\"year\").size().rename(\"row_count\").reset_index().sort_values(\"year\")\n",
    ")\n",
    "print(\"Row-level rows per year:\")\n",
    "print(row_counts.to_string(index=False))\n",
    "\n",
    "daily_year = None\n",
    "if \"date\" in daily.columns:\n",
    "    daily_year = pd.to_datetime(daily[\"date\"], errors=\"coerce\").dt.year\n",
    "elif \"datetime_raw\" in daily.columns:\n",
    "    daily_year = pd.to_datetime(daily[\"datetime_raw\"], errors=\"coerce\").dt.year\n",
    "if daily_year is not None:\n",
    "    daily_counts = (\n",
    "        daily.assign(year=daily_year).dropna(subset=[\"year\"]).groupby(\"year\").size().rename(\"daily_row_count\").reset_index().sort_values(\"year\")\n",
    "    )\n",
    "    print(\"Daily rows per year:\")\n",
    "    print(daily_counts.to_string(index=False))\n",
    "else:\n",
    "    print(\"No daily date available for yearly counts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78cec4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /Users/clee/Documents/Lab/mlife/data/weird/diet_log/diet_log_year_1969_rows.csv rows: 39\n"
     ]
    }
   ],
   "source": [
    "weird_dir = \"/Users/clee/Documents/Lab/mlife/data/weird/diet_log\"\n",
    "os.makedirs(weird_dir, exist_ok=True)\n",
    "df1969 = df.copy()\n",
    "if \"year\" not in df1969.columns:\n",
    "    if \"date\" in df1969.columns:\n",
    "        df1969[\"year\"] = pd.to_datetime(df1969[\"date\"], errors=\"coerce\").dt.year\n",
    "    elif \"datetime_raw\" in df1969.columns:\n",
    "        df1969[\"year\"] = pd.to_datetime(df1969[\"datetime_raw\"], errors=\"coerce\").dt.year\n",
    "df1969 = df1969[df1969[\"year\"] == 1969]\n",
    "out_path = os.path.join(weird_dir, \"diet_log_year_1969_rows.csv\")\n",
    "df1969.to_csv(out_path, index=False)\n",
    "print(\"Wrote:\", out_path, \"rows:\", len(df1969))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84e5e4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /Users/clee/Documents/Lab/mlife/data/weird/diet_log/unparsed_datetime_rows.csv rows: 14\n"
     ]
    }
   ],
   "source": [
    "weird_dir = \"/Users/clee/Documents/Lab/mlife/data/weird/diet_log\"\n",
    "os.makedirs(weird_dir, exist_ok=True)\n",
    "if \"datetime_raw\" in df.columns:\n",
    "    dt_series = df[\"datetime_raw\"]\n",
    "elif \"date\" in df.columns:\n",
    "    dt_series = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "else:\n",
    "    dt_series = pd.Series([pd.NaT] * len(df))\n",
    "df_unparsed = df[dt_series.isna()].copy()\n",
    "out_path = os.path.join(weird_dir, \"unparsed_datetime_rows.csv\")\n",
    "df_unparsed.to_csv(out_path, index=False)\n",
    "print(\"Wrote:\", out_path, \"rows:\", len(df_unparsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "900880b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: {'rows': 141844, 'daily_rows': 18824, 'participants': 106}\n",
      "Rows and unique participants by group:\n",
      "          Group  row_count  unique_participants\n",
      "   mLife+Points      87051                   54\n",
      "mLife (control)      54793                   52\n",
      "Rows by meal:\n",
      "     meal  row_count\n",
      "breakfast      42265\n",
      "   dinner      41437\n",
      "    lunch      37777\n",
      "    snack      20357\n",
      "      nan          8\n",
      "Per-participant row counts describe:\n",
      "count     106.000000\n",
      "mean     1338.150943\n",
      "std      1270.610995\n",
      "min         4.000000\n",
      "25%       366.250000\n",
      "50%       791.500000\n",
      "75%      2172.000000\n",
      "max      4823.000000\n",
      "Per-participant daily counts describe:\n",
      "count    106.000000\n",
      "mean     177.584906\n",
      "std      136.094006\n",
      "min        1.000000\n",
      "25%       50.500000\n",
      "50%      138.500000\n",
      "75%      345.000000\n",
      "max      374.000000\n",
      "Row-level nutrient availability (% non-missing):\n",
      "kcal         99.99\n",
      "protein_g    99.99\n",
      "carbs_g      99.99\n",
      "fat_g        99.99\n",
      "sugars_g     99.99\n",
      "fiber_g      99.99\n",
      "Daily nutrient availability (% non-missing):\n",
      "kcal         100.0\n",
      "protein_g    100.0\n",
      "carbs_g      100.0\n",
      "fat_g        100.0\n",
      "sugars_g     100.0\n",
      "fiber_g      100.0\n",
      "Group x Meal matrix:\n",
      "meal             breakfast  dinner  lunch  nan  snack\n",
      "Group                                                \n",
      "mLife (control)      16218   16063  14943    3   7566\n",
      "mLife+Points         26047   25374  22834    5  12791\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    canon\n",
    "except NameError:\n",
    "    def canon(s: str) -> str:\n",
    "        s = str(s).strip().lower()\n",
    "        s = re.sub(r\"[\\s\\-]+\", \"_\", s)\n",
    "        s = re.sub(r\"[^a-z0-9_]\", \"\", s)\n",
    "        return s\n",
    "colmap = {canon(c): c for c in df.columns}\n",
    "\n",
    "def find_col(cands):\n",
    "    for c in cands:\n",
    "        cc = canon(c)\n",
    "        if cc in colmap:\n",
    "            return colmap[cc]\n",
    "    return None\n",
    "group_col = find_col([\"group\", \"participant_group\", \"arm\", \"cohort\"]) or \"group\"\n",
    "summary = {}\n",
    "summary[\"rows\"] = len(df)\n",
    "summary[\"daily_rows\"] = len(daily) if \"daily\" in globals() else None\n",
    "summary[\"participants\"] = df[\"participant_id\"].nunique() if \"participant_id\" in df.columns else None\n",
    "print(\"Summary:\", summary)\n",
    "if isinstance(group_col, str) and group_col in df.columns:\n",
    "    grp_rows = df.groupby(group_col).size().rename(\"row_count\").reset_index().sort_values(\"row_count\", ascending=False)\n",
    "    grp_parts = df.groupby(group_col)[\"participant_id\"].nunique().rename(\"unique_participants\").reset_index()\n",
    "    grp = grp_rows.merge(grp_parts, on=group_col, how=\"left\")\n",
    "    print(\"Rows and unique participants by group:\")\n",
    "    print(grp.to_string(index=False))\n",
    "else:\n",
    "    print(\"No group column found.\")\n",
    "if \"meal\" in df.columns:\n",
    "    meal_counts = df[\"meal\"].value_counts(dropna=False).rename_axis(\"meal\").reset_index(name=\"row_count\")\n",
    "    print(\"Rows by meal:\")\n",
    "    print(meal_counts.to_string(index=False))\n",
    "if \"participant_id\" in df.columns:\n",
    "    per_part_rows = df.groupby(\"participant_id\").size().describe()\n",
    "    print(\"Per-participant row counts describe:\")\n",
    "    print(per_part_rows.to_string())\n",
    "if \"participant_id\" in daily.columns:\n",
    "    per_part_days = daily.groupby(\"participant_id\").size().describe()\n",
    "    print(\"Per-participant daily counts describe:\")\n",
    "    print(per_part_days.to_string())\n",
    "key_nutrients = [c for c in [\"kcal\",\"protein_g\",\"carbs_g\",\"fat_g\",\"sugars_g\",\"fiber_g\"] if c in df.columns]\n",
    "if key_nutrients:\n",
    "    avail = df[key_nutrients].notna().mean().mul(100).round(2)\n",
    "    print(\"Row-level nutrient availability (% non-missing):\")\n",
    "    print(avail.to_string())\n",
    "key_nutrients_daily = [c for c in [\"kcal\",\"protein_g\",\"carbs_g\",\"fat_g\",\"sugars_g\",\"fiber_g\"] if c in daily.columns]\n",
    "if key_nutrients_daily:\n",
    "    avail_d = daily[key_nutrients_daily].notna().mean().mul(100).round(2)\n",
    "    print(\"Daily nutrient availability (% non-missing):\")\n",
    "    print(avail_d.to_string())\n",
    "if isinstance(group_col, str) and group_col in df.columns and \"meal\" in df.columns:\n",
    "    gm = pd.crosstab(df[group_col], df[\"meal\"]) \n",
    "    print(\"Group x Meal matrix:\")\n",
    "    print(gm.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "187e8ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns ( 54 ):\n",
      "                  column          dtype  non_null  missing_%  unique\n",
      "              Brand Name         object     36198      74.48    3384\n",
      "            Nix Brand Id         object     39132      72.41    3411\n",
      "          Nix Brand Name         object     39132      72.41    3412\n",
      "             Nix Item Id         object     39132      72.41   10699\n",
      "           Nix Item Name         object     39131      72.41   10262\n",
      "            Alt Measures         object    105104      25.90    5550\n",
      "                 Og Unit         object    121004      14.69    1281\n",
      " Og Serving Weight Grams        float64    140680       0.82    2421\n",
      "Sel Serving Weight Grams        float64    140680       0.82    2702\n",
      "                     qty        float64    141573       0.19     720\n",
      "                     Qty         object    141813       0.02     936\n",
      "                    Meal         object    141836       0.01       4\n",
      "                 carbs_g        float64    141836       0.01    1334\n",
      "          cholesterol_mg        float64    141836       0.01    2216\n",
      "                    date         object    141830       0.01     377\n",
      "            datetime_raw datetime64[ns]    141830       0.01     377\n",
      "                     dow         object    141830       0.01       7\n",
      "                   fat_g        float64    141836       0.01     782\n",
      "                 fiber_g        float64    141836       0.01     335\n",
      "                    kcal        float64    141836       0.01    5609\n",
      "                   month        float64    141830       0.01      12\n",
      "            potassium_mg        float64    141836       0.01    6412\n",
      "               protein_g        float64    141836       0.01     810\n",
      "               sodium_mg        float64    141836       0.01    7505\n",
      "                sugars_g        float64    141836       0.01     876\n",
      "                    year        float64    141830       0.01       3\n",
      "                Added On         object    141844       0.00   59689\n",
      "                    Date         object    141844       0.00     380\n",
      "             Diet Log ID          int64    141844       0.00  141844\n",
      "               Food Name         object    141843       0.00   18714\n",
      "          Full Nutrients         object    141844       0.00   14736\n",
      "                   Group         object    141844       0.00       2\n",
      "         Nf Added Sugars         object    141844       0.00     834\n",
      "             Nf Calories         object    141844       0.00    5610\n",
      "          Nf Cholesterol         object    141844       0.00    2217\n",
      "        Nf Dietary Fiber         object    141844       0.00     336\n",
      "            Nf Potassium         object    141844       0.00    6413\n",
      "              Nf Protein         object    141844       0.00     811\n",
      "        Nf Saturated Fat         object    141844       0.00     420\n",
      "               Nf Sodium         object    141844       0.00    7506\n",
      "               Nf Sugars         object    141844       0.00     877\n",
      "   Nf Total Carbohydrate         object    141844       0.00    1335\n",
      "            Nf Total Fat         object    141844       0.00     783\n",
      "     Nf Trans Fatty Acid         object    141844       0.00     532\n",
      "                 Og Kcal        float64    141844       0.00    3941\n",
      "          Participant ID          int64    141844       0.00     106\n",
      "        Participant name         object    141844       0.00     106\n",
      "         Sel Serving Qty        float64    141844       0.00     360\n",
      "            Serving Type         object    141844       0.00    1556\n",
      "                   Thumb         object    141844       0.00    9755\n",
      "               food_name         object    141844       0.00   18715\n",
      "                    meal         object    141844       0.00       5\n",
      "          participant_id         object    141844       0.00     106\n",
      "            serving_type         object    141844       0.00    1556\n",
      "Proposed drop columns:\n",
      "['Alt Measures', 'Brand Name', 'Full Nutrients', 'Nix Brand Id', 'Nix Brand Name', 'Nix Item Id', 'Nix Item Name', 'Thumb']\n",
      "Note: cleaned outputs already omit non-essential columns via keep_cols.\n"
     ]
    }
   ],
   "source": [
    "cols_info = []\n",
    "for c in df.columns:\n",
    "    s = df[c]\n",
    "    cols_info.append({\n",
    "        \"column\": c,\n",
    "        \"dtype\": str(s.dtype),\n",
    "        \"non_null\": int(s.notna().sum()),\n",
    "        \"missing_%\": round(float(s.isna().mean()*100), 2),\n",
    "        \"unique\": int(s.nunique(dropna=True)),\n",
    "    })\n",
    "info_df = pd.DataFrame(cols_info).sort_values([\"missing_%\", \"column\"], ascending=[False, True])\n",
    "print(\"All columns (\", len(df.columns), \"):\")\n",
    "print(info_df.to_string(index=False))\n",
    "canon_map_cols = {c: c.strip().lower() for c in df.columns}\n",
    "pattern_drop = [c for c in df.columns if canon_map_cols[c].startswith(\"nix\")] \n",
    "explicit_drop = [c for c in df.columns if canon_map_cols[c] in {\"brand name\", \"thumb\", \"alt measures\", \"full nutrients\"}]\n",
    "high_missing_drop = info_df.loc[info_df[\"missing_%\"] >= 95, \"column\"].tolist()\n",
    "proposed_drop = sorted(set(pattern_drop + explicit_drop + high_missing_drop))\n",
    "print(\"Proposed drop columns:\")\n",
    "print(proposed_drop)\n",
    "print(\"Note: cleaned outputs already omit non-essential columns via keep_cols.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aed8ea0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default read_csv failed, trying python engine: Error tokenizing data. C error: Expected 35 fields in line 8, saw 50\n",
      "\n",
      "Raw shape: (148242, 35) Filtered shape: (148183, 35) Removed: 59\n",
      "Columns: 35\n",
      "                  column   dtype  non_null  missing_%  unique\n",
      "              Brand Name  object     37402      74.76    3383\n",
      "            Nix Brand Id  object     40378      72.75    3410\n",
      "          Nix Brand Name  object     40378      72.75    3411\n",
      "             Nix Item Id  object     40378      72.75   10697\n",
      "           Nix Item Name  object     40377      72.75   10260\n",
      "            Alt Measures  object    110232      25.61    5550\n",
      "                 Og Unit  object    126443      14.67    1280\n",
      " Og Serving Weight Grams float64    146977       0.81    2421\n",
      "Sel Serving Weight Grams float64    146977       0.81    2702\n",
      "                     Qty  object    148152       0.02     936\n",
      "                    Meal  object    148174       0.01       4\n",
      "                Added On  object    148183       0.00   61000\n",
      "                    Date  object    148183       0.00     376\n",
      "             Diet Log ID   int64    148183       0.00  148183\n",
      "               Food Name  object    148182       0.00   18711\n",
      "          Full Nutrients  object    148183       0.00   14734\n",
      "                   Group  object    148183       0.00       2\n",
      "         Nf Added Sugars  object    148183       0.00     834\n",
      "             Nf Calories  object    148183       0.00    5610\n",
      "          Nf Cholesterol  object    148183       0.00    2217\n",
      "        Nf Dietary Fiber  object    148183       0.00     336\n",
      "            Nf Potassium  object    148183       0.00    6413\n",
      "              Nf Protein  object    148183       0.00     811\n",
      "        Nf Saturated Fat  object    148183       0.00     420\n",
      "               Nf Sodium  object    148183       0.00    7505\n",
      "               Nf Sugars  object    148183       0.00     877\n",
      "   Nf Total Carbohydrate  object    148183       0.00    1335\n",
      "            Nf Total Fat  object    148183       0.00     783\n",
      "     Nf Trans Fatty Acid  object    148183       0.00     532\n",
      "                 Og Kcal float64    148183       0.00    3941\n",
      "          Participant ID   int64    148183       0.00     106\n",
      "        Participant name  object    148183       0.00     106\n",
      "         Sel Serving Qty float64    148183       0.00     360\n",
      "            Serving Type  object    148183       0.00    1556\n",
      "                   Thumb  object    148183       0.00    9754\n"
     ]
    }
   ],
   "source": [
    "raw_df = read_diet_csv(RAW_PATH)\n",
    "try:\n",
    "    canon\n",
    "except NameError:\n",
    "    def canon(s: str) -> str:\n",
    "        s = str(s).strip().lower()\n",
    "        s = re.sub(r\"[\\s\\-]+\", \"_\", s)\n",
    "        s = re.sub(r\"[^a-z0-9_]\", \"\", s)\n",
    "        return s\n",
    "cmap = {canon(c): c for c in raw_df.columns}\n",
    "\n",
    "def find_col(cands):\n",
    "    for c in cands:\n",
    "        cc = canon(c)\n",
    "        if cc in cmap:\n",
    "            return cmap[cc]\n",
    "    return None\n",
    "raw_date_col = find_col([\"date\", \"logged_date\", \"log_date\", \"added_on\", \"added on\", \"timestamp\", \"created_at\"]) or \"Date\"\n",
    "raw_dt = pd.to_datetime(raw_df[raw_date_col], errors=\"coerce\")\n",
    "bad_mask = raw_dt.isna() | (raw_dt.dt.year == 1969)\n",
    "df_raw_filtered = raw_df[~bad_mask].copy()\n",
    "print(\"Raw shape:\", raw_df.shape, \"Filtered shape:\", df_raw_filtered.shape, \"Removed:\", int(bad_mask.sum()))\n",
    "col_stats = []\n",
    "for c in df_raw_filtered.columns:\n",
    "    s = df_raw_filtered[c]\n",
    "    col_stats.append({\n",
    "        \"column\": c,\n",
    "        \"dtype\": str(s.dtype),\n",
    "        \"non_null\": int(s.notna().sum()),\n",
    "        \"missing_%\": round(float(s.isna().mean()*100), 2),\n",
    "        \"unique\": int(s.nunique(dropna=True)),\n",
    "    })\n",
    "quality = pd.DataFrame(col_stats).sort_values([\"missing_%\", \"column\"], ascending=[False, True])\n",
    "print(\"Columns:\", len(df_raw_filtered.columns))\n",
    "print(quality.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d15c39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: ['Nix Brand Id', 'Nix Brand Name', 'Nix Item Id', 'Nix Item Name', 'Brand Name']\n",
      "Renamed NF cols: ['added sugars', 'calories', 'cholesterol', 'dietary fiber', 'potassium', 'protein', 'saturated fat', 'sodium', 'sugars', 'total carbohydrate', 'total fat', 'trans fatty acid']\n",
      "Shape: (148183, 30)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diet Log ID</th>\n",
       "      <th>Participant name</th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Group</th>\n",
       "      <th>Date</th>\n",
       "      <th>Meal</th>\n",
       "      <th>Food Name</th>\n",
       "      <th>Thumb</th>\n",
       "      <th>Qty</th>\n",
       "      <th>Serving Type</th>\n",
       "      <th>calories</th>\n",
       "      <th>total fat</th>\n",
       "      <th>saturated fat</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>sodium</th>\n",
       "      <th>total carbohydrate</th>\n",
       "      <th>dietary fiber</th>\n",
       "      <th>sugars</th>\n",
       "      <th>protein</th>\n",
       "      <th>potassium</th>\n",
       "      <th>added sugars</th>\n",
       "      <th>trans fatty acid</th>\n",
       "      <th>Added On</th>\n",
       "      <th>Og Serving Weight Grams</th>\n",
       "      <th>Og Kcal</th>\n",
       "      <th>Og Unit</th>\n",
       "      <th>Sel Serving Qty</th>\n",
       "      <th>Sel Serving Weight Grams</th>\n",
       "      <th>Alt Measures</th>\n",
       "      <th>Full Nutrients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>152340</td>\n",
       "      <td>user user 10</td>\n",
       "      <td>10</td>\n",
       "      <td>mLife+Points</td>\n",
       "      <td>06/30/2023</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>deli turkey</td>\n",
       "      <td>https://nix-tag-images.s3.amazonaws.com/855_th...</td>\n",
       "      <td>3</td>\n",
       "      <td>oz</td>\n",
       "      <td>95.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>46.8</td>\n",
       "      <td>1020.6</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>11.5</td>\n",
       "      <td>296.8</td>\n",
       "      <td>11.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>06/30/2023 10:20:46 pm</td>\n",
       "      <td>56.7</td>\n",
       "      <td>63.50</td>\n",
       "      <td>oz</td>\n",
       "      <td>2.00</td>\n",
       "      <td>56.7</td>\n",
       "      <td>[{\"serving_weight\":48,\"measure\":\"oz (1 serving...</td>\n",
       "      <td>[{\"attr_id\":203,\"value\":7.6545},{\"attr_id\":204...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>152341</td>\n",
       "      <td>user user 10</td>\n",
       "      <td>10</td>\n",
       "      <td>mLife+Points</td>\n",
       "      <td>06/30/2023</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>fruit salad</td>\n",
       "      <td>https://nix-tag-images.s3.amazonaws.com/1773_t...</td>\n",
       "      <td>2</td>\n",
       "      <td>cup</td>\n",
       "      <td>193.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>49</td>\n",
       "      <td>6.5</td>\n",
       "      <td>32.9</td>\n",
       "      <td>2.7</td>\n",
       "      <td>728.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "      <td>06/30/2023 10:20:46 pm</td>\n",
       "      <td>162.4</td>\n",
       "      <td>96.62</td>\n",
       "      <td>cup</td>\n",
       "      <td>1.00</td>\n",
       "      <td>162.4</td>\n",
       "      <td>[{\"serving_weight\":162.4,\"measure\":\"cup\",\"seq\"...</td>\n",
       "      <td>[{\"attr_id\":203,\"value\":1.3555},{\"attr_id\":204...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152342</td>\n",
       "      <td>user user 10</td>\n",
       "      <td>10</td>\n",
       "      <td>mLife+Points</td>\n",
       "      <td>06/30/2023</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>hummus</td>\n",
       "      <td>https://nix-tag-images.s3.amazonaws.com/636_th...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>cup</td>\n",
       "      <td>99.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>227.4</td>\n",
       "      <td>8.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>136.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>06/30/2023 10:26:14 pm</td>\n",
       "      <td>60.0</td>\n",
       "      <td>99.60</td>\n",
       "      <td>cup</td>\n",
       "      <td>0.25</td>\n",
       "      <td>60.0</td>\n",
       "      <td>[{\"serving_weight\":15,\"measure\":\"tbsp\",\"seq\":1...</td>\n",
       "      <td>[{\"attr_id\":203,\"value\":4.74},{\"attr_id\":204,\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diet Log ID Participant name  Participant ID         Group        Date    Meal    Food Name                                              Thumb   Qty  \\\n",
       "0       152340     user user 10              10  mLife+Points  06/30/2023   Lunch  deli turkey  https://nix-tag-images.s3.amazonaws.com/855_th...     3   \n",
       "1       152341     user user 10              10  mLife+Points  06/30/2023   Lunch  fruit salad  https://nix-tag-images.s3.amazonaws.com/1773_t...     2   \n",
       "2       152342     user user 10              10  mLife+Points  06/30/2023  Dinner       hummus  https://nix-tag-images.s3.amazonaws.com/636_th...  0.25   \n",
       "\n",
       "  Serving Type calories total fat saturated fat cholesterol  sodium total carbohydrate dietary fiber sugars protein potassium added sugars trans fatty acid  \\\n",
       "0           oz     95.3       2.6           0.1        46.8  1020.6                6.5           0.3    3.4    11.5     296.8         11.5             11.5   \n",
       "1          cup    193.2       0.9           0.1           0     5.3                 49           6.5   32.9     2.7     728.3          2.7                0   \n",
       "2          cup     99.6       5.8           0.9           0   227.4                8.6           3.6    4.7     4.7     136.8          4.7              4.7   \n",
       "\n",
       "                 Added On  Og Serving Weight Grams  Og Kcal Og Unit  Sel Serving Qty  Sel Serving Weight Grams  \\\n",
       "0  06/30/2023 10:20:46 pm                     56.7    63.50      oz             2.00                      56.7   \n",
       "1  06/30/2023 10:20:46 pm                    162.4    96.62     cup             1.00                     162.4   \n",
       "2  06/30/2023 10:26:14 pm                     60.0    99.60     cup             0.25                      60.0   \n",
       "\n",
       "                                        Alt Measures                                     Full Nutrients  \n",
       "0  [{\"serving_weight\":48,\"measure\":\"oz (1 serving...  [{\"attr_id\":203,\"value\":7.6545},{\"attr_id\":204...  \n",
       "1  [{\"serving_weight\":162.4,\"measure\":\"cup\",\"seq\"...  [{\"attr_id\":203,\"value\":1.3555},{\"attr_id\":204...  \n",
       "2  [{\"serving_weight\":15,\"measure\":\"tbsp\",\"seq\":1...  [{\"attr_id\":203,\"value\":4.74},{\"attr_id\":204,\"...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nix_cols = [c for c in df_raw_filtered.columns if c.strip().lower().startswith(\"nix \")]\n",
    "drop_cols = nix_cols + [c for c in df_raw_filtered.columns if c.strip().lower() == \"brand name\"]\n",
    "df_raw_clean = df_raw_filtered.drop(columns=drop_cols, errors=\"ignore\").copy()\n",
    "rename_map = {c: re.sub(r\"(?i)^nf\\s+\", \"\", c).strip().lower() for c in df_raw_clean.columns if c.strip().lower().startswith(\"nf \")}\n",
    "df_raw_clean = df_raw_clean.rename(columns=rename_map)\n",
    "print(\"Dropped:\", drop_cols)\n",
    "print(\"Renamed NF cols:\", sorted(rename_map.values()))\n",
    "print(\"Shape:\", df_raw_clean.shape)\n",
    "df_raw_clean.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f65364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "meal_map = {\"breakfast\": 1, \"lunch\": 2, \"dinner\": 3, \"snack\": 4}\n",
    "try:\n",
    "    canon\n",
    "except NameError:\n",
    "    def canon(s: str) -> str:\n",
    "        s = str(s).strip().lower()\n",
    "        s = re.sub(r\"[\\s\\-]+\", \"_\", s)\n",
    "        s = re.sub(r\"[^a-z0-9_]\", \"\", s)\n",
    "        return s\n",
    "if \"df_raw_clean\" in globals():\n",
    "    colmap = {canon(c): c for c in df_raw_clean.columns}\n",
    "    def find_col(cands):\n",
    "        for c in cands:\n",
    "            cc = canon(c)\n",
    "            if cc in colmap:\n",
    "                return colmap[cc]\n",
    "        return None\n",
    "    meal_col = find_col([\"meal\", \"meal_type\", \"meal type\", \"meal_name\", \"category\"])\n",
    "    if meal_col is not None:\n",
    "        df_raw_clean[\"meal_code\"] = (\n",
    "            df_raw_clean[meal_col].astype(str).str.strip().str.lower().map(meal_map).astype(\"Int64\")\n",
    "        )\n",
    "        print(df_raw_clean[\"meal_code\"].value_counts(dropna=False).sort_index())\n",
    "    else:\n",
    "        print(\"No meal-like column found in df_raw_clean.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5571f38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    canon\n",
    "except NameError:\n",
    "    import re\n",
    "    def canon(s: str) -> str:\n",
    "        s = str(s).strip().lower()\n",
    "        s = re.sub(r\"[\\s\\-]+\", \"_\", s)\n",
    "        s = re.sub(r\"[^a-z0-9_]\", \"\", s)\n",
    "        return s\n",
    "\n",
    "def _norm_meal(x):\n",
    "    t = str(x).strip().lower()\n",
    "    m = {\"b\": \"breakfast\", \"breakfast\": \"breakfast\", \"l\": \"lunch\", \"lnch\": \"lunch\", \"lunch\": \"lunch\", \"d\": \"dinner\", \"din\": \"dinner\", \"dinner\": \"dinner\", \"snack\": \"snack\", \"snacks\": \"snack\"}\n",
    "    return m.get(t)\n",
    "\n",
    "meal_map = {\"breakfast\": 1, \"lunch\": 2, \"dinner\": 3, \"snack\": 4}\n",
    "\n",
    "if \"df\" in globals() and \"meal\" in df.columns:\n",
    "    df[\"meal_code\"] = df[\"meal\"].map(lambda x: meal_map.get(_norm_meal(x))).astype(\"Int64\")\n",
    "    if \"meal_code\" in df.columns:\n",
    "        print(\"df meal_code value counts:\")\n",
    "        print(df[\"meal_code\"].value_counts(dropna=False).sort_index().to_string())\n",
    "\n",
    "if \"df_raw_clean\" in globals():\n",
    "    cmap = {canon(c): c for c in df_raw_clean.columns}\n",
    "    meal_col = None\n",
    "    for cand in [\"meal\", \"meal_type\", \"meal name\", \"meal_name\", \"category\"]:\n",
    "        cc = canon(cand)\n",
    "        if cc in cmap:\n",
    "            meal_col = cmap[cc]\n",
    "            break\n",
    "    if meal_col is not None:\n",
    "        df_raw_clean[\"meal_code\"] = df_raw_clean[meal_col].map(lambda x: meal_map.get(_norm_meal(x))).astype(\"Int64\")\n",
    "        print(\"df_raw_clean meal_code value counts:\")\n",
    "        print(df_raw_clean[\"meal_code\"].value_counts(dropna=False).sort_index().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "960b0fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready: call save_filtered_outputs() to write cleaned artifacts.\n"
     ]
    }
   ],
   "source": [
    "def save_filtered_outputs():\n",
    "    os.makedirs(CLEAN_DIR, exist_ok=True)\n",
    "    # Row-level export (exclude unparsed dates and 1969)\n",
    "    if 'df' in globals():\n",
    "        cols_base = [c for c in [\"participant_id\", \"datetime_raw\", \"date\", \"year\", \"month\", \"dow\", \"meal\", \"meal_code\", \"food_name\", \"qty\", \"serving_type\"] if c in df.columns]\n",
    "        cols_nutr = [c for c in [\"kcal\", \"protein_g\", \"carbs_g\", \"fat_g\", \"sugars_g\", \"fiber_g\", \"sodium_mg\", \"cholesterol_mg\", \"potassium_mg\"] if c in df.columns]\n",
    "        keep_cols = cols_base + cols_nutr\n",
    "        df_out = df.loc[df.get(\"date\").notna() & (df.get(\"year\") != 1969)].copy() if (\"date\" in df.columns and \"year\" in df.columns) else df.copy()\n",
    "        rowlevel_out = os.path.join(CLEAN_DIR, \"diet_log_rowlevel_cleaned_v2.csv\")\n",
    "        df_out[keep_cols].to_csv(rowlevel_out, index=False)\n",
    "        print(\"row-level:\", rowlevel_out, len(df_out), \"rows\", len(keep_cols), \"cols\")\n",
    "    else:\n",
    "        print(\"df not defined; skipping row-level export\")\n",
    "\n",
    "    # Daily aggregates export (exclude unparsed and 1969)\n",
    "    if 'daily' in globals():\n",
    "        if all(c in daily.columns for c in [\"date\", \"year\"]):\n",
    "            daily_out_df = daily.loc[daily[\"date\"].notna() & (daily[\"year\"] != 1969)].copy()\n",
    "        else:\n",
    "            daily_out_df = daily.copy()\n",
    "        daily_out = os.path.join(CLEAN_DIR, \"diet_log_daily_ml_ready.csv\")\n",
    "        daily_out_df.to_csv(daily_out, index=False)\n",
    "        print(\"daily:\", daily_out, len(daily_out_df), \"rows\")\n",
    "    else:\n",
    "        print(\"daily not defined; skipping daily export\")\n",
    "\n",
    "    # Save raw pruned/renamed dataset\n",
    "    if 'df_raw_clean' in globals():\n",
    "        raw_pruned_out = os.path.join(CLEAN_DIR, \"diet_log_raw_pruned.csv\")\n",
    "        df_raw_clean.to_csv(raw_pruned_out, index=False)\n",
    "        print(\"raw-pruned:\", raw_pruned_out, len(df_raw_clean), \"rows\", df_raw_clean.shape[1], \"cols\")\n",
    "    else:\n",
    "        print(\"df_raw_clean not defined; skipping raw-pruned export\")\n",
    "\n",
    "    # Export column-quality report for df_raw_filtered\n",
    "    if 'df_raw_filtered' in globals():\n",
    "        reports_dir = os.path.join(CLEAN_DIR, \"reports\")\n",
    "        os.makedirs(reports_dir, exist_ok=True)\n",
    "        total = len(df_raw_filtered)\n",
    "        rows = []\n",
    "        for c in df_raw_filtered.columns:\n",
    "            s = df_raw_filtered[c]\n",
    "            non_null = int(s.notna().sum())\n",
    "            missing = total - non_null\n",
    "            nunique = int(s.nunique(dropna=True))\n",
    "            rows.append({\n",
    "                \"column\": c,\n",
    "                \"dtype\": str(s.dtype),\n",
    "                \"non_null\": non_null,\n",
    "                \"total\": total,\n",
    "                \"missing\": missing,\n",
    "                \"missing_pct\": round((missing / total) * 100, 3) if total else 0.0,\n",
    "                \"nunique\": nunique,\n",
    "            })\n",
    "        qual_df = pd.DataFrame(rows).sort_values([\"missing_pct\", \"nunique\", \"column\"], ascending=[True, False, True])\n",
    "        qual_out = os.path.join(reports_dir, \"diet_log_raw_filtered_column_quality.csv\")\n",
    "        qual_df.to_csv(qual_out, index=False)\n",
    "        print(\"raw-filtered quality:\", qual_out, len(qual_df), \"rows\")\n",
    "    else:\n",
    "        print(\"df_raw_filtered not defined; skipping column-quality export\")\n",
    "\n",
    "print(\"Ready: call save_filtered_outputs() to write cleaned artifacts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db42aafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row-level: /Users/clee/Documents/Lab/mlife/data/cleaned/diet_log_rowlevel_cleaned_v2.csv 141791 rows 19 cols\n",
      "daily: /Users/clee/Documents/Lab/mlife/data/cleaned/diet_log_daily_ml_ready.csv 18824 rows\n",
      "raw-pruned: /Users/clee/Documents/Lab/mlife/data/cleaned/diet_log_raw_pruned.csv 148183 rows 30 cols\n",
      "raw-filtered quality: /Users/clee/Documents/Lab/mlife/data/cleaned/reports/diet_log_raw_filtered_column_quality.csv 35 rows\n"
     ]
    }
   ],
   "source": [
    "print(\"No files will be written automatically. To export, run: enable_writes(True); save_filtered_outputs(out_dir='tmp')\")ts(out_dir=\"tmp\"):\n",
    "    base_dir = TMP_DIR if str(out_dir).lower() == \"tmp\" else CLEAN_DIR\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    if not WRITE_ENABLED:\n",
    "        print(\"[SKIP WRITE] WRITE_ENABLED is False; no files will be created.\")\n",
    "        return\n",
    "\n",
    "    # Row-level export (exclude unparsed dates and 1969)\n",
    "    if 'df' in globals():\n",
    "        cols_base = [c for c in [\"participant_id\", \"datetime_raw\", \"date\", \"year\", \"month\", \"dow\", \"meal\", \"meal_code\", \"food_name\", \"qty\", \"serving_type\"] if c in df.columns]\n",
    "        cols_nutr = [c for c in [\"kcal\", \"protein_g\", \"carbs_g\", \"fat_g\", \"sugars_g\", \"fiber_g\", \"sodium_mg\", \"cholesterol_mg\", \"potassium_mg\"] if c in df.columns]\n",
    "        keep_cols = cols_base + cols_nutr\n",
    "        df_out = df.loc[df.get(\"date\").notna() & (df.get(\"year\") != 1969)].copy() if (\"date\" in df.columns and \"year\" in df.columns) else df.copy()\n",
    "        rowlevel_out = os.path.join(base_dir, \"diet_log_rowlevel_cleaned_v2.csv\")\n",
    "        df_out[keep_cols].to_csv(rowlevel_out, index=False)\n",
    "        print(\"row-level ->\", rowlevel_out, len(df_out), \"rows\", len(keep_cols), \"cols\")\n",
    "    else:\n",
    "        print(\"df not defined; skipping row-level export\")\n",
    "\n",
    "    # Daily aggregates export (exclude unparsed and 1969)\n",
    "    if 'daily' in globals():\n",
    "        if all(c in daily.columns for c in [\"date\", \"year\"]):\n",
    "            daily_out_df = daily.loc[daily[\"date\"].notna() & (daily[\"year\"] != 1969)].copy()\n",
    "        else:\n",
    "            daily_out_df = daily.copy()\n",
    "        daily_out = os.path.join(base_dir, \"diet_log_daily_ml_ready.csv\")\n",
    "        daily_out_df.to_csv(daily_out, index=False)\n",
    "        print(\"daily ->\", daily_out, len(daily_out_df), \"rows\")\n",
    "    else:\n",
    "        print(\"daily not defined; skipping daily export\")\n",
    "\n",
    "    # Save raw pruned/renamed dataset\n",
    "    if 'df_raw_clean' in globals():\n",
    "        raw_pruned_out = os.path.join(base_dir, \"diet_log_raw_pruned.csv\")\n",
    "        df_raw_clean.to_csv(raw_pruned_out, index=False)\n",
    "        print(\"raw-pruned ->\", raw_pruned_out, len(df_raw_clean), \"rows\", df_raw_clean.shape[1], \"cols\")\n",
    "    else:\n",
    "        print(\"df_raw_clean not defined; skipping raw-pruned export\")\n",
    "\n",
    "    # Export column-quality report for df_raw_filtered\n",
    "    if 'df_raw_filtered' in globals():\n",
    "        reports_dir = os.path.join(base_dir, \"reports\")\n",
    "        os.makedirs(reports_dir, exist_ok=True)\n",
    "        total = len(df_raw_filtered)\n",
    "        rows = []\n",
    "        for c in df_raw_filtered.columns:\n",
    "            s = df_raw_filtered[c]\n",
    "            non_null = int(s.notna().sum())\n",
    "            missing = total - non_null\n",
    "            nunique = int(s.nunique(dropna=True))\n",
    "            rows.append({\n",
    "                \"column\": c,\n",
    "                \"dtype\": str(s.dtype),\n",
    "                \"non_null\": non_null,\n",
    "                \"total\": total,\n",
    "                \"missing\": missing,\n",
    "                \"missing_pct\": round((missing / total) * 100, 3) if total else 0.0,\n",
    "                \"nunique\": nunique,\n",
    "            })\n",
    "        qual_df = pd.DataFrame(rows).sort_values([\"missing_pct\", \"nunique\", \"column\"], ascending=[True, False, True])\n",
    "        qual_out = os.path.join(reports_dir, \"diet_log_raw_filtered_column_quality.csv\")\n",
    "        qual_df.to_csv(qual_out, index=False)\n",
    "        print(\"raw-filtered quality ->\", qual_out, len(qual_df), \"rows\")\n",
    "    else:\n",
    "        print(\"df_raw_filtered not defined; skipping column-quality export\")\n",
    "\n",
    "print(\"Ready: writes are disabled by default. Call enable_writes(True) and save_filtered_outputs(out_dir='tmp') to export to tmp.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
